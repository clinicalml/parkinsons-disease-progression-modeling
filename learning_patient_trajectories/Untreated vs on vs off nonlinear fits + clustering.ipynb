{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt, math\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../../datasets/ppmi/visit_feature_inputs_asof_2019Jan24_using_CMEDTM/'\n",
    "pd_total_df = pd.read_csv(data_dir + 'PD_totals_across_time.csv')\n",
    "pd_questions_df = pd.read_csv(data_dir + 'PD_questions_across_time.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select 20 patients to use for visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(82073)\n",
    "patnos = pd_total_df.PATNO.unique()\n",
    "np.random.shuffle(patnos)\n",
    "selected_patnos = np.empty(20)\n",
    "idx = 0\n",
    "for patno in patnos:\n",
    "    if idx == 20:\n",
    "        break\n",
    "    patno_df = pd_total_df.loc[pd_total_df['PATNO']==patno]\n",
    "    patno_df = patno_df.dropna(subset=['NUPDRS3_untreated', 'NUPDRS3_off', 'NUPDRS3_on'], \\\n",
    "                               how='all').sort_values(by=['EVENT_ID_DUR'])\n",
    "    if len(patno_df) >= 5:\n",
    "        selected_patnos[idx] = patno\n",
    "        idx += 1\n",
    "selected_patnos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate subtotals across time split by treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_4cond_cols(cols):\n",
    "    # returns untreated, off, on, maob\n",
    "    untreated_cols = []\n",
    "    off_cols = []\n",
    "    on_cols = []\n",
    "    maob_cols = []\n",
    "    for col in cols:\n",
    "        if col.startswith('NP3'):\n",
    "            untreated_cols.append(col+'_untreated')\n",
    "            off_cols.append(col+'_off')\n",
    "            on_cols.append(col+'_on')\n",
    "            maob_cols.append(col+'_maob')\n",
    "        else:\n",
    "            untreated_cols.append(col)\n",
    "            off_cols.append(col)\n",
    "            on_cols.append(col)\n",
    "            maob_cols.append(col)\n",
    "    return untreated_cols, off_cols, on_cols, maob_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cond_sum(df, cols, sum_col):\n",
    "    df[sum_col] = np.where(pd.isnull(df[cols[0]]), float('NaN'), df[cols].sum(axis=1))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tremor_cols = ['NP3RTALL', 'NP3RTALU', 'NP3KTRML', 'NP3PTRML', 'NP3KTRMR', 'NP3PTRMR', 'NP3RTARU', \\\n",
    "                   'NP3RTALJ', 'NP3RTARL', 'NP2TRMR', 'NP3RTCON']\n",
    "rigidity_left_cols = ['NP3RIGLU', 'NP3RIGLL', 'NP3PRSPL', 'NP3FTAPL', 'NP3HMOVL', 'NP3LGAGL', 'NP3TTAPL']\n",
    "rigidity_right_cols = ['NP3RIGRL', 'NP3RIGRU', 'NP3PRSPR', 'NP3FTAPR', 'NP3HMOVR', 'NP3LGAGR', 'NP3TTAPR']\n",
    "face_cols = ['NP3SPCH', 'NP3RIGN', 'NP3BRADY', 'NP3FACXP']\n",
    "gait_cols = ['NP3FRZGT', 'NP3PSTBL', 'NP3RISNG', 'NP3GAIT', 'NP3POSTR']\n",
    "subtotal_cols_dict = {'NUPDRS_TREMOR': tremor_cols, 'NUPDRS_RIGIDITY_LEFT': rigidity_left_cols, \\\n",
    "                      'NUPDRS_RIGIDITY_RIGHT': rigidity_right_cols, 'NUPDRS_FACE': face_cols, \\\n",
    "                      'NUPDRS_GAIT': gait_cols}\n",
    "for subtotal in subtotal_cols_dict.keys():\n",
    "    subtotal_untreated_cols, subtotal_off_cols, subtotal_on_cols, subtotal_maob_cols \\\n",
    "        = get_4cond_cols(subtotal_cols_dict[subtotal])\n",
    "    pd_questions_df = get_cond_sum(pd_questions_df, subtotal_untreated_cols, subtotal + '_untreated')\n",
    "    pd_questions_df = get_cond_sum(pd_questions_df, subtotal_off_cols, subtotal + '_off')\n",
    "    pd_questions_df = get_cond_sum(pd_questions_df, subtotal_on_cols, subtotal + '_on')\n",
    "    pd_questions_df = get_cond_sum(pd_questions_df, subtotal_maob_cols, subtotal + '_maob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_on_off_sums(df, cols, sum_header):\n",
    "    df[sum_header + '_untreated'] = np.where(~pd.isnull(df['NP3RTALL_untreated']), df[cols].sum(axis=1), float('NaN'))\n",
    "    df[sum_header + '_treated'] = np.where(~pd.isnull(df['NP3RTALL_untreated']), float('NaN'), df[cols].sum(axis=1))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_activities = ['NP2HWRT', 'NP2FREZ', 'NP2HYGN', 'NP2EAT', 'NP2HOBB', 'NP2WALK', 'NP2DRES', 'NP2RISE', \\\n",
    "                    'NP2TURN', 'NP2SWAL', 'NP2SALV', 'NP2SPCH']\n",
    "pd_questions_df = get_on_off_sums(pd_questions_df, daily_activities, 'NUPDRS_DAILYACT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_questions_df = pd_questions_df.merge(pd_total_df[['PATNO','EVENT_ID','NUPDRS3_untreated','NUPDRS3_on',\\\n",
    "                                                     'NUPDRS3_off','NUPDRS3_maob']], \\\n",
    "                                       on=['PATNO','EVENT_ID'], how='left', validate='one_to_one')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit curves to each treatment setting and make plots for each patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_func(x, a, b):\n",
    "    return a*x + b\n",
    "\n",
    "def quadratic_func(x, a, b, c):\n",
    "    return a*x**2 + b*x + c\n",
    "\n",
    "def piecewise_lin_func(x, a, b, c, d, e):\n",
    "    return np.piecewise(x, [x < e], [lambda x: a*x + b, lambda x: c*x + d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nupdrs_col_headers = ['NUPDRS_TREMOR', 'NUPDRS_RIGIDITY_LEFT', 'NUPDRS_RIGIDITY_RIGHT', 'NUPDRS_FACE', 'NUPDRS_GAIT', \\\n",
    "                      'NUPDRS_DAILYACT', 'NUPDRS3']\n",
    "nupdrs_col_labels = ['Tremor', 'Rigidity left', 'Rigidity right', 'Face', 'Gait', 'Part II', 'Part III']\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "def make_mdsupdrs_plot(df, func_fit='linear', offset=0):\n",
    "    assert func_fit in {'linear', 'piecewise_linear', 'quadratic'}\n",
    "    if func_fit == 'linear':\n",
    "        func = lin_func\n",
    "        num_params = 2\n",
    "    elif func_fit == 'piecewise_linear':\n",
    "        func = piecewise_lin_func\n",
    "        num_params = 5\n",
    "    else:\n",
    "        func = quadratic_func\n",
    "        num_params = 3\n",
    "    # to avoid misspecification, the number of points must be at least the number of parameters before fitting\n",
    "    num_rows = 5\n",
    "    num_cols = len(nupdrs_col_headers)\n",
    "    fig, ax = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(4*num_cols, 4*num_rows))\n",
    "    for row_idx in range(num_rows):\n",
    "        patno = selected_patnos[row_idx+offset]\n",
    "        patno_df = df.loc[df['PATNO']==patno]\n",
    "        for col_idx in range(len(nupdrs_col_headers)):\n",
    "            col_header = nupdrs_col_headers[col_idx]\n",
    "            if col_header != 'NUPDRS_DAILYACT':\n",
    "                patno_col_df = patno_df.dropna(subset=[col_header+'_untreated',col_header+'_off',col_header+'_on',\\\n",
    "                                               col_header+'_maob'], \\\n",
    "                                       how='all').sort_values(by=['EVENT_ID_DUR'])\n",
    "            else:\n",
    "                patno_col_df = patno_df.dropna(subset=[col_header+'_untreated',col_header+'_treated'], \\\n",
    "                                       how='all').sort_values(by=['EVENT_ID_DUR'])\n",
    "       \n",
    "            untreated_df = patno_col_df.dropna(subset=[col_header+'_untreated'])\n",
    "            untreated_times = untreated_df.EVENT_ID_DUR.values\n",
    "            untreated_values = untreated_df[col_header+'_untreated'].values\n",
    "            if len(untreated_times) > 0:\n",
    "                ax[row_idx, col_idx].scatter(untreated_times, untreated_values, c='b', label='untreated')\n",
    "                if len(untreated_times) >= num_params:\n",
    "                    untreated_params, _ = curve_fit(func, untreated_times, untreated_values)\n",
    "                    untreated_smooth_xs = 0.01*np.arange(100*np.min(untreated_times), 100*np.max(untreated_times))\n",
    "                    ax[row_idx, col_idx].plot(untreated_smooth_xs, func(untreated_smooth_xs, *untreated_params), 'b')\n",
    "            ax[row_idx, col_idx].set_title(nupdrs_col_labels[col_idx])\n",
    "            if col_header != 'NUPDRS_DAILYACT':\n",
    "                off_df = patno_col_df.dropna(subset=[col_header+'_off'])\n",
    "                off_times = off_df.EVENT_ID_DUR.values\n",
    "                off_values = off_df[col_header+'_off'].values\n",
    "                if len(off_times) > 0:\n",
    "                    ax[row_idx, col_idx].scatter(off_times, off_values, c='g', label='\"off\" meds')\n",
    "                    if len(off_times) >= num_params:\n",
    "                        off_params, _ = curve_fit(func, off_times, off_values)\n",
    "                        off_smooth_xs = 0.01*np.arange(100*np.min(off_times), 100*np.max(off_times))\n",
    "                        ax[row_idx, col_idx].plot(off_smooth_xs, func(off_smooth_xs, *off_params), 'g')\n",
    "\n",
    "                on_df = patno_col_df.dropna(subset=[col_header+'_on'])\n",
    "                on_times = on_df.EVENT_ID_DUR.values\n",
    "                on_values = on_df[col_header+'_on'].values\n",
    "                if len(on_times) > 0:\n",
    "                    ax[row_idx, col_idx].scatter(on_times, on_values, c='r', label='\"on\" meds')\n",
    "                    if len(on_times) >= num_params:\n",
    "                        on_params, _ = curve_fit(func, on_times, on_values)\n",
    "                        \n",
    "                        on_smooth_xs = 0.01*np.arange(100*np.min(on_times), 100*np.max(on_times))\n",
    "                        ax[row_idx, col_idx].plot(on_smooth_xs, func(on_smooth_xs, *on_params), 'r')\n",
    "\n",
    "                maob_df = patno_col_df.dropna(subset=[col_header+'_maob'])\n",
    "                maob_times = maob_df.EVENT_ID_DUR.values\n",
    "                maob_values = maob_df[col_header+'_maob'].values\n",
    "                if len(maob_times) > 0:\n",
    "                    ax[row_idx, col_idx].scatter(maob_times, maob_values, c='y', label='MAO-B')\n",
    "                    if len(maob_times) >= num_params:\n",
    "                        maob_params, _ = curve_fit(func, maob_times, maob_values)\n",
    "                        maob_smooth_xs = 0.01*np.arange(100*np.min(maob_times), 100*np.max(maob_times))\n",
    "                        ax[row_idx, col_idx].plot(maob_smooth_xs, func(maob_smooth_xs, *maob_params), 'y')\n",
    "            else:\n",
    "                treated_df = patno_col_df.dropna(subset=[col_header+'_treated'])\n",
    "                treated_times = treated_df.EVENT_ID_DUR.values\n",
    "                treated_values = treated_df[col_header+'_treated'].values\n",
    "                if len(treated_times) > 0:\n",
    "                    ax[row_idx, col_idx].scatter(treated_times, treated_values, c='r', label='treated')\n",
    "                    if len(treated_times) >= num_params:\n",
    "                        treated_params, _ = curve_fit(func, treated_times, treated_values)\n",
    "                        treated_smooth_xs = 0.01*np.arange(100*np.min(treated_times), 100*np.max(treated_times))\n",
    "                        ax[row_idx, col_idx].plot(treated_smooth_xs, func(treated_smooth_xs, *treated_params), 'r')\n",
    "                        \n",
    "    plt.tight_layout()\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_mdsupdrs_plot(pd_questions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_mdsupdrs_plot(pd_questions_df, offset=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_mdsupdrs_plot(pd_questions_df, func_fit='piecewise_linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_mdsupdrs_plot(pd_questions_df, func_fit='piecewise_linear', offset=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_mdsupdrs_plot(pd_questions_df, func_fit='quadratic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_mdsupdrs_plot(pd_questions_df, func_fit='quadratic', offset=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick function using MSE + changepoint restriction for piecewise functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_calc(x, y, func, *params):\n",
    "    return np.mean(np.square(y - func(x, *params)))\n",
    "\n",
    "def pick_func(x, y):\n",
    "    # returns best function + its parameters\n",
    "    if len(x) < 2:\n",
    "        return None\n",
    "    lin_params, _ = curve_fit(lin_func, x, y)\n",
    "    if len(x) < 3:\n",
    "        return lin_func, lin_params\n",
    "    lin_mse = mse_calc(x, y, lin_func, *lin_params)\n",
    "    quadratic_params, _ = curve_fit(quadratic_func, x, y)\n",
    "    quadratic_mse = mse_calc(x, y, quadratic_func, *quadratic_params)\n",
    "    if len(x) >= 5:\n",
    "        piecewise_lin_params, _ = curve_fit(piecewise_lin_func, x, y)\n",
    "        if piecewise_lin_params[-1] < x[1] or piecewise_lin_params[-1] > x[-2]:\n",
    "            piecewise_lin_mse = float('inf')\n",
    "        else:\n",
    "            piecewise_lin_mse = mse_calc(x, y, piecewise_lin_func, *piecewise_lin_params)\n",
    "    else:\n",
    "        piecewise_lin_mse = float('inf')\n",
    "    if lin_mse <= quadratic_mse and lin_mse <= piecewise_lin_mse:\n",
    "        return lin_func, lin_params\n",
    "    elif quadratic_mse <= piecewise_lin_mse:\n",
    "        return quadratic_func, quadratic_params\n",
    "    else:\n",
    "        return piecewise_lin_func, piecewise_lin_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nupdrs_col_headers = ['NUPDRS_TREMOR', 'NUPDRS_RIGIDITY_LEFT', 'NUPDRS_RIGIDITY_RIGHT', 'NUPDRS_FACE', 'NUPDRS_GAIT', \\\n",
    "                      'NUPDRS_DAILYACT', 'NUPDRS3']\n",
    "nupdrs_col_labels = ['Tremor', 'Rigidity left', 'Rigidity right', 'Face', 'Gait', 'Part II', 'Part III']\n",
    "plt.rcParams.update({'font.size': 24})\n",
    "nupdrs_col_maxs = [15, 20, 20, 12, 12, 27, 60]\n",
    "nupdrs_col_mins = [0, 0, 0, 0, 0, 0, 0]\n",
    "def make_mdsupdrs_plot_pick_func(df, offset=0):\n",
    "    num_rows = 5\n",
    "    num_cols = len(nupdrs_col_headers)\n",
    "    fig, ax = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(4*num_cols, 4*num_rows))\n",
    "    for row_idx in range(num_rows):\n",
    "        patno = selected_patnos[row_idx+offset]\n",
    "        patno_df = df.loc[df['PATNO']==patno]\n",
    "        for col_idx in range(len(nupdrs_col_headers)):\n",
    "            col_header = nupdrs_col_headers[col_idx]\n",
    "            if col_header != 'NUPDRS_DAILYACT':\n",
    "                patno_col_df = patno_df.dropna(subset=[col_header+'_untreated',col_header+'_off',col_header+'_on',\\\n",
    "                                               col_header+'_maob'], \\\n",
    "                                       how='all').sort_values(by=['EVENT_ID_DUR'])\n",
    "            else:\n",
    "                patno_col_df = patno_df.dropna(subset=[col_header+'_untreated',col_header+'_treated'], \\\n",
    "                                       how='all').sort_values(by=['EVENT_ID_DUR'])\n",
    "       \n",
    "            untreated_df = patno_col_df.dropna(subset=[col_header+'_untreated'])\n",
    "            untreated_times = untreated_df.EVENT_ID_DUR.values\n",
    "            untreated_values = untreated_df[col_header+'_untreated'].values\n",
    "            if len(untreated_times) > 0:\n",
    "                ax[row_idx, col_idx].scatter(untreated_times, untreated_values, c='b', label='untreated')\n",
    "                if len(untreated_times) >= 2:\n",
    "                    untreated_func, untreated_params = pick_func(untreated_times, untreated_values)\n",
    "                    untreated_smooth_xs = 0.01*np.arange(100*np.min(untreated_times), 100*np.max(untreated_times))\n",
    "                    ax[row_idx, col_idx].plot(untreated_smooth_xs, \\\n",
    "                                              untreated_func(untreated_smooth_xs, *untreated_params), 'b', linewidth=4)\n",
    "            ax[row_idx, col_idx].set_title(nupdrs_col_labels[col_idx])\n",
    "            ax[row_idx, col_idx].set_ylim([nupdrs_col_mins[col_idx], nupdrs_col_maxs[col_idx]])\n",
    "            if col_header != 'NUPDRS_DAILYACT':\n",
    "                off_df = patno_col_df.dropna(subset=[col_header+'_off'])\n",
    "                off_times = off_df.EVENT_ID_DUR.values\n",
    "                off_values = off_df[col_header+'_off'].values\n",
    "                if len(off_times) > 0:\n",
    "                    ax[row_idx, col_idx].scatter(off_times, off_values, c='g', label='\"off\" meds')\n",
    "                    if len(off_times) >= 2:\n",
    "                        off_func, off_params = pick_func(off_times, off_values)\n",
    "                        off_smooth_xs = 0.01*np.arange(100*np.min(off_times), 100*np.max(off_times))\n",
    "                        ax[row_idx, col_idx].plot(off_smooth_xs, off_func(off_smooth_xs, *off_params), 'g', \\\n",
    "                                                  linestyle='dashdot', linewidth=4)\n",
    "\n",
    "                on_df = patno_col_df.dropna(subset=[col_header+'_on'])\n",
    "                on_times = on_df.EVENT_ID_DUR.values\n",
    "                on_values = on_df[col_header+'_on'].values\n",
    "                if len(on_times) > 0:\n",
    "                    ax[row_idx, col_idx].scatter(on_times, on_values, c='r', label='\"on\" meds')\n",
    "                    if len(on_times) >= 2:\n",
    "                        on_func, on_params = pick_func(on_times, on_values)\n",
    "                        on_smooth_xs = 0.01*np.arange(100*np.min(on_times), 100*np.max(on_times))\n",
    "                        ax[row_idx, col_idx].plot(on_smooth_xs, on_func(on_smooth_xs, *on_params), 'r', \\\n",
    "                                                  linestyle='dotted', linewidth=4)\n",
    "\n",
    "                maob_df = patno_col_df.dropna(subset=[col_header+'_maob'])\n",
    "                maob_times = maob_df.EVENT_ID_DUR.values\n",
    "                maob_values = maob_df[col_header+'_maob'].values\n",
    "                if len(maob_times) > 0:\n",
    "                    ax[row_idx, col_idx].scatter(maob_times, maob_values, c='y', label='MAO-B')\n",
    "                    if len(maob_times) >= 2:\n",
    "                        maob_func, maob_params = pick_func(maob_times, maob_values)\n",
    "                        maob_smooth_xs = 0.01*np.arange(100*np.min(maob_times), 100*np.max(maob_times))\n",
    "                        ax[row_idx, col_idx].plot(maob_smooth_xs, maob_func(maob_smooth_xs, *maob_params), 'y', \\\n",
    "                                                  linestyle='dashed', linewidth=4)\n",
    "            else:\n",
    "                treated_df = patno_col_df.dropna(subset=[col_header+'_treated'])\n",
    "                treated_times = treated_df.EVENT_ID_DUR.values\n",
    "                treated_values = treated_df[col_header+'_treated'].values\n",
    "                if len(treated_times) > 0:\n",
    "                    ax[row_idx, col_idx].scatter(treated_times, treated_values, c='r', label='treated')\n",
    "                    if len(treated_times) >= 2:\n",
    "                        treated_func, treated_params = pick_func(treated_times, treated_values)\n",
    "                        treated_smooth_xs = 0.01*np.arange(100*np.min(treated_times), 100*np.max(treated_times))\n",
    "                        ax[row_idx, col_idx].plot(treated_smooth_xs, \\\n",
    "                                                  treated_func(treated_smooth_xs, *treated_params), 'r', \\\n",
    "                                                  linestyle='dotted', linewidth=4)\n",
    "                        \n",
    "    plt.tight_layout()\n",
    "    plt.legend()\n",
    "    plt.savefig('nupdrs_subtotals_nonlinear_offset' + str(offset) + '_asof_2019Jul31.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_mdsupdrs_plot_pick_func(pd_questions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_mdsupdrs_plot_pick_func(pd_questions_df, offset=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run k-means clustering on parameters and classify clusters from baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patient_params(patno_df):\n",
    "    # returns dict: subtotal -> {medication state: 7 params}, 0 if missing state\n",
    "    patno_param_dict = dict()\n",
    "    for col_header in nupdrs_col_headers:\n",
    "        patno_param_dict[col_header] = dict()\n",
    "        if col_header == 'NUPDRS_DAILYACT':\n",
    "            col_endings = {'untreated', 'treated'}\n",
    "        else:\n",
    "            col_endings = {'untreated', 'on', 'off', 'maob'}\n",
    "        for col_ending in col_endings:\n",
    "            patno_col_df = patno_df.dropna(subset=[col_header + '_' + col_ending])\n",
    "            patno_col_times = patno_col_df.EVENT_ID_DUR.values\n",
    "            patno_col_values = patno_col_df[col_header + '_' + col_ending].values\n",
    "            if len(patno_col_times) < 2:\n",
    "                patno_param_dict[col_header][col_ending] = np.zeros(7)\n",
    "            else:\n",
    "                _, func_params = pick_func(patno_col_times, patno_col_values)\n",
    "                if len(func_params) == 2: #linear\n",
    "                    formatted_params = np.array([0, func_params[0], func_params[1], \\\n",
    "                                                 0, func_params[0], func_params[1], 0])\n",
    "                elif len(func_params) == 3: # quadratic\n",
    "                    formatted_params = np.array([func_params[0], func_params[1], func_params[2], \\\n",
    "                                                 func_params[0], func_params[1], func_params[2], 0])\n",
    "                else: #piecewise linear\n",
    "                    formatted_params = np.array([0, func_params[0], func_params[1], \\\n",
    "                                                 0, func_params[2], func_params[3], func_params[4]])\n",
    "                patno_param_dict[col_header][col_ending] = formatted_params\n",
    "    return patno_param_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "patno_params_dict = dict()\n",
    "for patno in pd_questions_df.PATNO.unique():\n",
    "    print(patno)\n",
    "    patno_df = pd_questions_df.loc[pd_questions_df['PATNO']==patno]\n",
    "    patno_params_dict[patno] = get_patient_params(patno_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patno_params_dict[3001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather parameters\n",
    "patnos = patno_params_dict.keys()\n",
    "param_cols = []\n",
    "subtotals = patno_params_dict[patnos[0]].keys()\n",
    "subtotals.sort()\n",
    "for subtotal in subtotals:\n",
    "    subtotal_settings = patno_params_dict[patnos[0]][subtotal].keys()\n",
    "    subtotal_settings.sort()\n",
    "    for treatment_setting in subtotal_settings:\n",
    "        param_cols.append(subtotal + '_' + treatment_setting)\n",
    "patno_params_arr = np.empty((len(patnos), len(param_cols)*7))\n",
    "print(patno_params_arr.shape)\n",
    "for patno_idx in range(len(patnos)):\n",
    "    patno = patnos[patno_idx]\n",
    "    param_idx = 0\n",
    "    for subtotal in subtotals:\n",
    "        subtotal_settings = patno_params_dict[patnos[0]][subtotal].keys()\n",
    "        subtotal_settings.sort()\n",
    "        for treatment_setting in subtotal_settings:\n",
    "            patno_params_arr[patno_idx, param_idx:param_idx+7] = patno_params_dict[patno][subtotal][treatment_setting]\n",
    "            param_idx += 7\n",
    "    assert param_idx == patno_params_arr.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_2clusters = KMeans(n_clusters=2, random_state=0).fit(patno_params_arr)\n",
    "cluster0_idxs = np.nonzero(np.where(kmeans_2clusters.labels_ == 0, 1, 0))[0]\n",
    "cluster1_idxs = np.nonzero(kmeans_2clusters.labels_)[0]\n",
    "print(len(cluster0_idxs))\n",
    "print(len(cluster1_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_2clusters.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_3clusters = KMeans(n_clusters=3, random_state=0).fit(patno_params_arr)\n",
    "cluster0_idxs = np.nonzero(np.where(kmeans_3clusters.labels_ == 0, 1, 0))[0]\n",
    "cluster1_idxs = np.nonzero(np.where(kmeans_3clusters.labels_ == 1, 1, 0))[0]\n",
    "cluster2_idxs = np.nonzero(np.where(kmeans_3clusters.labels_ == 2, 1, 0))[0]\n",
    "print(len(cluster0_idxs))\n",
    "print(len(cluster1_idxs))\n",
    "print(len(cluster2_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_8clusters = KMeans(n_clusters=8, random_state=0).fit(patno_params_arr)\n",
    "for idx in range(8):\n",
    "    print(len(np.nonzero(np.where(kmeans_8clusters.labels_ == idx, 1, 0))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_4clusters = KMeans(n_clusters=4, random_state=0).fit(patno_params_arr)\n",
    "for idx in range(4):\n",
    "    print(len(np.nonzero(np.where(kmeans_4clusters.labels_ == idx, 1, 0))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_5clusters = KMeans(n_clusters=5, random_state=0).fit(patno_params_arr)\n",
    "for idx in range(5):\n",
    "    print(len(np.nonzero(np.where(kmeans_5clusters.labels_ == idx, 1, 0))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_6clusters = KMeans(n_clusters=6, random_state=0).fit(patno_params_arr)\n",
    "for idx in range(6):\n",
    "    print(len(np.nonzero(np.where(kmeans_6clusters.labels_ == idx, 1, 0))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_7clusters = KMeans(n_clusters=7, random_state=0).fit(patno_params_arr)\n",
    "for idx in range(7):\n",
    "    print(len(np.nonzero(np.where(kmeans_7clusters.labels_ == idx, 1, 0))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 7 clusters - study the 2 largest clusters\n",
    "cluster0_idxs = np.nonzero(np.where(kmeans_7clusters.labels_ == 0, 1, 0))[0]\n",
    "cluster1_idxs = np.nonzero(np.where(kmeans_7clusters.labels_ == 2, 1, 0))[0]\n",
    "cluster0_patnos = np.array(patnos)[cluster0_idxs]\n",
    "cluster1_patnos = np.array(patnos)[cluster1_idxs]\n",
    "cluster0_params = np.array(patno_params_arr)[cluster0_idxs]\n",
    "cluster1_params = np.array(patno_params_arr)[cluster1_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_7_cols = []\n",
    "letters = ['a','b','c','d','e','f','g']\n",
    "for col in param_cols:\n",
    "    for letter in letters:\n",
    "        param_7_cols.append(col + '_' + letter)\n",
    "signif_param_idxs = []\n",
    "for param_idx in range(patno_params_arr.shape[1]):\n",
    "    _, pval = ttest_ind(cluster0_params[:,param_idx], cluster1_params[:,param_idx], equal_var=False)\n",
    "    if pval < 0.05:\n",
    "        signif_param_idxs.append(param_idx)\n",
    "        print(param_7_cols[param_idx] + ': {0:.4f}'.format(np.mean(cluster0_params[:,param_idx])) \\\n",
    "              + ' ({0:.4f}), '.format(np.std(cluster0_params[:,param_idx])) \\\n",
    "              + '{0:.4f}'.format(np.mean(cluster1_params[:,param_idx])) \\\n",
    "              + ' ({0:.4f})'.format(np.std(cluster1_params[:,param_idx])))\n",
    "#print(np.array(param_7_cols)[signif_param_idxs])\n",
    "print(len(signif_param_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_7_cols = []\n",
    "letters = ['a','b','c','d','e','f','g']\n",
    "for col in param_cols:\n",
    "    for letter in letters:\n",
    "        param_7_cols.append(col + '_' + letter)\n",
    "signif_param_idxs = []\n",
    "for param_idx in range(patno_params_arr.shape[1]):\n",
    "    _, pval = ttest_ind(cluster0_params[:,param_idx], cluster1_params[:,param_idx], equal_var=False)\n",
    "    if pval < 0.0005:\n",
    "        signif_param_idxs.append(param_idx)\n",
    "        print(param_7_cols[param_idx] + ': {0:.4f}'.format(np.mean(cluster0_params[:,param_idx])) \\\n",
    "              + ' ({0:.4f}), '.format(np.std(cluster0_params[:,param_idx])) \\\n",
    "              + '{0:.4f}'.format(np.mean(cluster1_params[:,param_idx])) \\\n",
    "              + ' ({0:.4f})'.format(np.std(cluster1_params[:,param_idx])))\n",
    "#print(np.array(param_7_cols)[signif_param_idxs])\n",
    "print(len(signif_param_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get significantly different baseline features\n",
    "datadir = '../gather_PD_data/'\n",
    "baseline_df = pd.read_csv(datadir + 'selected_baseline_data_using_CMEDTM.csv')\n",
    "del baseline_df['ENROLL_CAT']\n",
    "longitudinal_df = pd.read_csv(datadir + 'selected_longitudinal_data_using_CMEDTM.csv')\n",
    "screening_longitudinal_df = longitudinal_df.loc[longitudinal_df['EVENT_ID_DUR']==0]\n",
    "baseline_longitudinal_df = longitudinal_df.loc[longitudinal_df['EVENT_ID_DUR']==0.125]\n",
    "screening_longitudinal_cols = ['NUPDRS1', 'MOCA', 'NUPDRS2_DAILYACT', 'NUPDRS3_GAIT', 'NUPDRS3_RIGID_RIGHT', \\\n",
    "                               'NUPDRS3_FACE', 'NUPDRS3_TREMOR', 'NUPDRS3_RIGID_LEFT']\n",
    "baseline_longitudinal_cols = ['SCOPA-AUT', 'HVLT_discrim_recog', 'STAI', 'HVLT_immed_recall', 'QUIP', 'EPWORTH', \\\n",
    "                              'GDSSHORT', 'HVLT_retent', 'BJLO', 'LNS', 'SEMANTIC_FLUENCY', 'REMSLEEP']\n",
    "baseline_df = baseline_df.merge(screening_longitudinal_df[['PATNO']+screening_longitudinal_cols], on=['PATNO'], \\\n",
    "                                validate='one_to_one')\n",
    "baseline_df = baseline_df.merge(baseline_longitudinal_df[['PATNO']+baseline_longitudinal_cols], on=['PATNO'], \\\n",
    "                                validate='one_to_one')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster0_baseline_df = baseline_df.loc[baseline_df['PATNO'].isin(cluster0_patnos)]\n",
    "cluster1_baseline_df = baseline_df.loc[baseline_df['PATNO'].isin(cluster1_patnos)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signif_baseline_feats = []\n",
    "for col in baseline_df.columns.values[1:]:\n",
    "    cluster0_col = cluster0_baseline_df[col].dropna().values\n",
    "    cluster1_col = cluster1_baseline_df[col].dropna().values\n",
    "    _, pval = ttest_ind(cluster0_col, cluster1_col, equal_var=False)\n",
    "    if pval < 0.0005:\n",
    "        signif_baseline_feats.append(col)\n",
    "        print(col + ': {0:.4f}'.format(np.mean(cluster0_col)) + ' ({0:.4f}), '.format(np.std(cluster0_col)) \\\n",
    "              + '{0:.4f}'.format(np.mean(cluster1_col)) + ' ({0:.4f})'.format(np.std(cluster1_col)))\n",
    "#print(signif_baseline_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signif_baseline_feats = []\n",
    "for col in baseline_df.columns.values[1:]:\n",
    "    cluster0_col = cluster0_baseline_df[col].dropna().values\n",
    "    cluster1_col = cluster1_baseline_df[col].dropna().values\n",
    "    _, pval = ttest_ind(cluster0_col, cluster1_col, equal_var=False)\n",
    "    if pval < 0.05:\n",
    "        signif_baseline_feats.append(col)\n",
    "        print(col + ': {0:.4f}'.format(np.mean(cluster0_col)) + ' ({0:.4f}), '.format(np.std(cluster0_col)) \\\n",
    "              + '{0:.4f}'.format(np.mean(cluster1_col)) + ' ({0:.4f})'.format(np.std(cluster1_col)))\n",
    "#print(signif_baseline_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signif_baseline_feats = []\n",
    "for col in baseline_df.columns.values[1:]:\n",
    "    cluster0_col = cluster0_baseline_df[col].dropna().values\n",
    "    cluster1_col = cluster1_baseline_df[col].dropna().values\n",
    "    _, pval = ttest_ind(cluster0_col, cluster1_col, equal_var=False)\n",
    "    if pval < 0.005:\n",
    "        signif_baseline_feats.append(col)\n",
    "        print(col + ': {0:.4f}'.format(np.mean(cluster0_col)) + ' ({0:.4f}), '.format(np.std(cluster0_col)) \\\n",
    "              + '{0:.4f}'.format(np.mean(cluster1_col)) + ' ({0:.4f})'.format(np.std(cluster1_col)))\n",
    "#print(signif_baseline_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the proportion of patients that use each functional form\n",
    "# linear if a = 0 and g = 0\n",
    "# quadratic if a != 0\n",
    "# piecewise linear if g != 0\n",
    "setting_counts = dict()\n",
    "for subtotal in patno_params_dict[patnos[0]].keys():\n",
    "    setting_counts[subtotal] = dict()\n",
    "    for setting in patno_params_dict[patnos[0]][subtotal].keys():\n",
    "        setting_counts[subtotal][setting] = {'linear': 0, 'piecewise_linear': 0, 'quadratic': 0}\n",
    "for patno in patno_params_dict.keys():\n",
    "    for subtotal in patno_params_dict[patno].keys():\n",
    "        for setting in patno_params_dict[patno][subtotal].keys():\n",
    "            params = patno_params_dict[patno][subtotal][setting]\n",
    "            if len(np.nonzero(params)[0]) > 0:\n",
    "                if params[0] != 0:\n",
    "                    setting_counts[subtotal][setting]['quadratic'] += 1\n",
    "                elif params[-1] != 0:\n",
    "                    setting_counts[subtotal][setting]['piecewise_linear'] += 1\n",
    "                else:\n",
    "                    setting_counts[subtotal][setting]['linear'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(setting_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get proportion of patients with each functional form in each cluster\n",
    "cluster0_setting_counts = dict()\n",
    "cluster1_setting_counts = dict()\n",
    "for subtotal in patno_params_dict[patnos[0]].keys():\n",
    "    cluster0_setting_counts[subtotal] = dict()\n",
    "    cluster1_setting_counts[subtotal] = dict()\n",
    "    for setting in patno_params_dict[patnos[0]][subtotal].keys():\n",
    "        cluster0_setting_counts[subtotal][setting] = {'linear': 0, 'piecewise_linear': 0, 'quadratic': 0}\n",
    "        cluster1_setting_counts[subtotal][setting] = {'linear': 0, 'piecewise_linear': 0, 'quadratic': 0}\n",
    "for patno in patno_params_dict.keys():\n",
    "    for subtotal in patno_params_dict[patno].keys():\n",
    "        for setting in patno_params_dict[patno][subtotal].keys():\n",
    "            params = patno_params_dict[patno][subtotal][setting]\n",
    "            if len(np.nonzero(params)[0]) > 0:\n",
    "                if patno in cluster0_patnos:\n",
    "                    if params[0] != 0:\n",
    "                        cluster0_setting_counts[subtotal][setting]['quadratic'] += 1\n",
    "                    elif params[-1] != 0:\n",
    "                        cluster0_setting_counts[subtotal][setting]['piecewise_linear'] += 1\n",
    "                    else:\n",
    "                        cluster0_setting_counts[subtotal][setting]['linear'] += 1\n",
    "                elif patno in cluster1_patnos:\n",
    "                    if params[0] != 0:\n",
    "                        cluster1_setting_counts[subtotal][setting]['quadratic'] += 1\n",
    "                    elif params[-1] != 0:\n",
    "                        cluster1_setting_counts[subtotal][setting]['piecewise_linear'] += 1\n",
    "                    else:\n",
    "                        cluster1_setting_counts[subtotal][setting]['linear'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cluster0_setting_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cluster1_setting_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make barplots for each set of distributions\n",
    "def make_barplot(setting_counts, cluster0_setting_counts, cluster1_settting_counts):\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    subtotals = setting_counts.keys()\n",
    "    part3_total_idx = subtotals.index('NUPDRS3') # move this to end\n",
    "    subtotals = subtotals[:part3_total_idx] + subtotals[part3_total_idx+1:] + ['NUPDRS3']\n",
    "    fig, ax = plt.subplots(nrows=4, ncols=len(subtotals), sharey=True, sharex=True, figsize=(20,10))\n",
    "    for subtotal_idx in range(len(subtotals)):\n",
    "        subtotal = subtotals[subtotal_idx]\n",
    "        if subtotal == 'NUPDRS_DAILYACT':\n",
    "            settings = ['untreated', 'treated']\n",
    "        else:\n",
    "            settings = ['untreated', 'on', 'off', 'maob']\n",
    "        for row_idx in range(len(settings)):\n",
    "            # plot order: linear, quadratic, piecewise linear\n",
    "            setting = settings[row_idx]\n",
    "            total_y = np.array([setting_counts[subtotal][setting]['linear'], \\\n",
    "                                setting_counts[subtotal][setting]['quadratic'], \\\n",
    "                                setting_counts[subtotal][setting]['piecewise_linear']])\n",
    "            cluster0_y = np.array([cluster0_setting_counts[subtotal][setting]['linear'], \\\n",
    "                                   cluster0_setting_counts[subtotal][setting]['quadratic'], \\\n",
    "                                   cluster0_setting_counts[subtotal][setting]['piecewise_linear']])\n",
    "            cluster1_y = np.array([cluster1_setting_counts[subtotal][setting]['linear'], \\\n",
    "                                   cluster1_setting_counts[subtotal][setting]['quadratic'], \\\n",
    "                                   cluster1_setting_counts[subtotal][setting]['piecewise_linear']])\n",
    "            x = np.array([0,1,2])\n",
    "            ax[row_idx,subtotal_idx].bar(x-0.2, total_y, width=0.2, color='b', align='center', label='Total')\n",
    "            ax[row_idx,subtotal_idx].bar(x, cluster0_y, width=0.2, color='g', align='center', label='Cluster 0')\n",
    "            ax[row_idx,subtotal_idx].bar(x+0.2, cluster1_y, width=0.2, color='r', align='center', label='Cluster 1')\n",
    "        if subtotal == 'NUPDRS3':\n",
    "            subtotal_title = 'Part III total'\n",
    "        else:\n",
    "            subtotal_title = subtotal[7:].lower().replace('_', ' ')\n",
    "        ax[0,subtotal_idx].set_title(subtotal_title)\n",
    "        ax[3,subtotal_idx].set_xticklabels(['','linear','quadratic','piecewise_linear'], rotation=90)\n",
    "    for row_idx in range(len(settings)):\n",
    "        ax[row_idx,0].set_ylabel(settings[row_idx])\n",
    "    ax[3,len(subtotals)-1].legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_barplot(setting_counts, cluster0_setting_counts, cluster1_setting_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "differences don't seem to be in distribution of functional forms<br>\n",
    "Also seems to be generating more dimensions than originally present in data...is this only to handle diff # of data points?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
