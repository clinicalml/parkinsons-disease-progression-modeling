{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, pickle, matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '../../../datasets/ppmi/visit_feature_inputs_asof_2019Jan24_using_CMEDTM/'\n",
    "pd_totals_df = pd.read_csv(datadir + 'PD_totals_across_time.csv')\n",
    "outcome_path = '../ppmi_survival_models/survival_outcome_subtotals_gdsfixed_using_CMEDTM/set_3.0_0.5_2019Jul08/' \\\n",
    "    + 'cohorts_time_event_dict.pkl'\n",
    "with open(outcome_path, 'r') as f:\n",
    "    pd_surv_df = pickle.load(f)['PD']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine a T for censoring approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_visits_df = pd_totals_df.sort_values(by=['EVENT_ID_DUR']).drop_duplicates(subset=['PATNO'], keep='last')\n",
    "last_visits_df.EVENT_ID_DUR.plot.hist()\n",
    "plt.xlabel('Time enrolled (years)')\n",
    "plt.ylabel('# patients')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print('# patients with at least ' + str(i) + ' years enrolled: ' \\\n",
    "          + str(len(last_visits_df.loc[last_visits_df['EVENT_ID_DUR']>=i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_totals_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_totals_df['NUPDRS3_any'] = np.where(~pd.isnull(pd_totals_df['NUPDRS3_untreated']), \\\n",
    "                                       pd_totals_df['NUPDRS3_untreated'], \\\n",
    "                                       np.where(~pd.isnull(pd_totals_df['NUPDRS3_off']), \\\n",
    "                                                pd_totals_df['NUPDRS3_off'], \\\n",
    "                                                np.where(~pd.isnull(pd_totals_df['NUPDRS3_on']), \\\n",
    "                                                         pd_totals_df['NUPDRS3_on'], \\\n",
    "                                                         pd_totals_df['NUPDRS3_maob'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totals_used = ['SCOPA-AUT', 'HVLT_discrim_recog', 'HVLT_immed_recall', 'NUPDRS3_any', 'QUIP', 'EPWORTH', \\\n",
    "               'STATE_ANXIETY', 'TRAIT_ANXIETY', 'NUPDRS2', 'HVLT_retent', 'BJLO', 'MOCA', 'LNS', 'SEMANTIC_FLUENCY', \\\n",
    "               'REMSLEEP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actually need 2nd to last visit for enroll time due to censoring\n",
    "pd_totals_df['PATNO_EVENT_ID_DUR'] = pd_totals_df['PATNO'].astype(str) + pd_totals_df['EVENT_ID_DUR'].astype(str)\n",
    "pd_totals_df_nonan = pd_totals_df.dropna(subset=totals_used)\n",
    "last_visits_df = pd_totals_df_nonan.sort_values(by=['EVENT_ID_DUR']).drop_duplicates(subset=['PATNO'], keep='last')\n",
    "second_to_last_visits_df \\\n",
    "    = pd_totals_df_nonan.loc[~pd_totals_df_nonan['PATNO_EVENT_ID_DUR'].isin(last_visits_df['PATNO_EVENT_ID_DUR'])]\n",
    "second_to_last_visits_df \\\n",
    "    = second_to_last_visits_df.sort_values(by=['EVENT_ID_DUR']).drop_duplicates(subset=['PATNO'], keep='last')\n",
    "second_to_last_visits_df.EVENT_ID_DUR.plot.hist()\n",
    "plt.xlabel('Time enrolled (years)')\n",
    "plt.ylabel('# patients')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print('# patients with at least ' + str(i) + ' years enrolled: ' \\\n",
    "          + str(len(second_to_last_visits_df.loc[second_to_last_visits_df['EVENT_ID_DUR']>=i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_totals_df.EVENT_ID_DUR.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = ['Motor', 'Autonomic', 'Cognitive', 'Sleep', 'Psychiatric']\n",
    "ts = [3.125, 3.625, 4.125, 4.625, 5.125]\n",
    "fig, ax = plt.subplots(nrows=len(outcomes), ncols=len(ts), figsize=(12,10), sharex=True, sharey=True)\n",
    "plt.rcParams.update({'font.size':12})\n",
    "obs_before_ts_dict = dict()\n",
    "obs_after_ts_dict = dict()\n",
    "cens_after_ts_dict = dict()\n",
    "for idx in range(len(ts)):\n",
    "    obs_before_ts_dict[ts[idx]] = []\n",
    "    obs_after_ts_dict[ts[idx]] = []\n",
    "    cens_after_ts_dict[ts[idx]] = []\n",
    "    patnos_enrolled_at_least_i_years \\\n",
    "        = set(second_to_last_visits_df.loc[second_to_last_visits_df['EVENT_ID_DUR']>=ts[idx]].PATNO.values.tolist())\n",
    "    #print('Require at least ' + str(ts[idx]) + ' years of enrollment: ' \\\n",
    "    #      + str(len(patnos_enrolled_at_least_i_years)) + ' patients')\n",
    "    pd_surv_df_atleast_i = pd_surv_df.loc[pd_surv_df['PATNO'].isin(patnos_enrolled_at_least_i_years)]\n",
    "    for outcome_idx in range(len(outcomes)):\n",
    "        outcome = outcomes[outcome_idx]\n",
    "        assert len(pd_surv_df_atleast_i.loc[np.logical_and(pd_surv_df_atleast_i[outcome + '_T'] < ts[idx], \\\n",
    "                                                           pd_surv_df_atleast_i[outcome + '_E']==0)])== 0\n",
    "        pd_surv_df_atleast_i[outcome + '_T_atleast' + str(ts[idx])] \\\n",
    "            = np.where(pd_surv_df_atleast_i[outcome + '_E']==0, ts[idx] + 0.25, \\\n",
    "                       pd_surv_df_atleast_i[outcome + '_T']) # set censored to max time\n",
    "        pd_surv_df_atleast_i[outcome + '_T_atleast' + str(ts[idx])] \\\n",
    "            = np.where(pd_surv_df_atleast_i[outcome + '_T_atleast' + str(ts[idx])] >= ts[idx] + 0.25, ts[idx] + 0.25, \\\n",
    "                       pd_surv_df_atleast_i[outcome + '_T_atleast' + str(ts[idx])]) # set larger observed to max time\n",
    "        ax[outcome_idx, idx].hist(pd_surv_df_atleast_i[outcome + '_T_atleast' + str(ts[idx])])\n",
    "        ax[outcome_idx, idx].set_xlabel(outcome + ' (T=' + str(ts[idx]) + ')')\n",
    "        ax[outcome_idx, idx].set_ylabel('# patients')\n",
    "        #print(outcome + ': ' + str(pd_surv_df_atleast_i[outcome + '_E'].sum()) + ' observed, ' \\\n",
    "        #      + str(len(pd_surv_df_atleast_i) - pd_surv_df_atleast_i[outcome + '_E'].sum()) + ' censored')\n",
    "        num_obs_before_t \\\n",
    "            = len(pd_surv_df_atleast_i.loc[np.logical_and(pd_surv_df_atleast_i[outcome + '_E']==1, \\\n",
    "                                                          pd_surv_df_atleast_i[outcome + '_T'] <= ts[idx] + 0.25)])\n",
    "        obs_before_ts_dict[ts[idx]].append(num_obs_before_t)\n",
    "        num_obs_after_t \\\n",
    "            = len(pd_surv_df_atleast_i.loc[np.logical_and(pd_surv_df_atleast_i[outcome + '_E']==1, \\\n",
    "                                                          pd_surv_df_atleast_i[outcome + '_T'] > ts[idx] + 0.25)])\n",
    "        obs_after_ts_dict[ts[idx]].append(num_obs_after_t)\n",
    "        num_cens_after_t = len(pd_surv_df_atleast_i.loc[pd_surv_df_atleast_i[outcome + '_E']==0])\n",
    "        cens_after_ts_dict[ts[idx]].append(num_cens_after_t)\n",
    "plt.suptitle('Imputed time to observation (yrs)')\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.savefig('impute_obs_time_distribs.pdf')\n",
    "plt.show()\n",
    "if len(ts) == 3:\n",
    "    x_offsets = [-0.1, 0.0, 0.1]\n",
    "elif len(ts) == 4:\n",
    "    x_offsets = [-0.15, -0.05, 0.05, 0.15]\n",
    "elif len(ts) == 5:\n",
    "    x_offsets = [-0.2, -0.1, 0, 0.1, 0.2]\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "for idx in range(len(ts)):\n",
    "    if idx == 0:\n",
    "        labels = ['observed before T', 'observed after T', 'censored after T']\n",
    "    else:\n",
    "        labels = [None, None, None]\n",
    "    ax.bar(np.arange(len(outcomes))+x_offsets[idx], obs_before_ts_dict[ts[idx]], align='center', width=0.09, \\\n",
    "           label=labels[0], color='red')\n",
    "    ax.bar(np.arange(len(outcomes))+x_offsets[idx], obs_after_ts_dict[ts[idx]], align='center', width=0.09, \\\n",
    "           bottom=obs_before_ts_dict[ts[idx]], label=labels[1], color='green')\n",
    "    ax.bar(np.arange(len(outcomes))+x_offsets[idx], cens_after_ts_dict[ts[idx]], align='center', width=0.09, \\\n",
    "           bottom=np.array(obs_before_ts_dict[ts[idx]]) + np.array(obs_after_ts_dict[ts[idx]]), \\\n",
    "           label=labels[2], color='blue')\n",
    "ax.set_xticklabels([''] + outcomes)\n",
    "ts_str = 'T = ('\n",
    "for t in ts:\n",
    "    ts_str += str(t) + ', '\n",
    "ts_str = ts_str[:-2] + ')'\n",
    "ax.set_xlabel(ts_str)\n",
    "ax.set_ylabel('# patients')\n",
    "plt.legend()\n",
    "plt.savefig('obs_cens_around_T.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting T = 4.125 seems to be the best trade-off between sample size and cutting off too many observations. Psychiatric would be the only outcome that has a lot of observations after the cutoff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize outcomes in pairwise plots and t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seaborn import heatmap\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = ['Motor', 'Autonomic', 'Cognitive', 'Sleep', 'Psychiatric']\n",
    "patnos_enrolled_at_least_i_years \\\n",
    "    = set(second_to_last_visits_df.loc[second_to_last_visits_df['EVENT_ID_DUR']>=4.125].PATNO.values.tolist())\n",
    "pd_surv_df_atleast_i = pd_surv_df.loc[pd_surv_df['PATNO'].isin(patnos_enrolled_at_least_i_years)]\n",
    "outcome_T_atleast_i_cols = []\n",
    "for outcome in outcomes:\n",
    "    pd_surv_df_atleast_i[outcome + '_T_atleast' + str(4.125)] \\\n",
    "        = np.where(pd_surv_df_atleast_i[outcome + '_E']==0, 4.125 + 0.5, \\\n",
    "                   pd_surv_df_atleast_i[outcome + '_T']) # set censored to max time\n",
    "    pd_surv_df_atleast_i[outcome + '_T_atleast' + str(4.125)] \\\n",
    "        = np.where(pd_surv_df_atleast_i[outcome + '_T_atleast' + str(4.125)] >= 4.125 + 0.5, 4.125 + 0.5, \\\n",
    "                   pd_surv_df_atleast_i[outcome + '_T_atleast' + str(4.125)]) # set larger observed to max time\n",
    "    outcome_T_atleast_i_cols.append(outcome + '_T_atleast' + str(4.125))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_surv_df_atleast_i.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_T_atleast_i = [outcome + '_T_atleast4.125' for outcome in outcomes]\n",
    "tsne_2comp_data = TSNE().fit_transform(pd_surv_df_atleast_i[outcome_T_atleast_i].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_1comp_data = TSNE(n_components=1).fit_transform(pd_surv_df_atleast_i[outcome_T_atleast_i].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(tsne_2comp_data[:,0], tsne_2comp_data[:,1])\n",
    "plt.xlabel('Component 1')\n",
    "plt.ylabel('Component 2')\n",
    "plt.title('t-SNE on 5 outcome times with T=4.125')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_ts = [0., 0.125, 0.375, 0.625, 0.875, 1.125, 1.625, 2.125, 2.625, 3.125, 3.625, 4.125, 4.625]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 14})\n",
    "for outcome in outcomes:\n",
    "    T_early_idx = np.nonzero(np.where(pd_surv_df_atleast_i[outcome + '_T_atleast4.125']<1, 1, 0))[0]\n",
    "    T_middle_idx = np.nonzero(np.where(np.logical_and(pd_surv_df_atleast_i[outcome + '_T_atleast4.125']>=1, \\\n",
    "                                                      pd_surv_df_atleast_i[outcome + '_T_atleast4.125']<2.5), \\\n",
    "                                       1, 0))[0]\n",
    "    T_late_idx = np.nonzero(np.where(np.logical_and(pd_surv_df_atleast_i[outcome + '_T_atleast4.125']>=2.5, \\\n",
    "                                                    pd_surv_df_atleast_i[outcome + '_T_atleast4.125']<4.5), 1, 0))[0]\n",
    "    T_at_end_idx = np.nonzero(np.where(pd_surv_df_atleast_i[outcome + '_T_atleast4.125']==4.625, 1, 0))[0]\n",
    "    assert len(T_early_idx) + len(T_middle_idx) + len(T_late_idx) + len(T_at_end_idx) == len(pd_surv_df_atleast_i)\n",
    "    plt.scatter(tsne_2comp_data[T_early_idx,0], tsne_2comp_data[T_early_idx,1], color='green', label='0-0.875')\n",
    "    plt.scatter(tsne_2comp_data[T_middle_idx,0], tsne_2comp_data[T_middle_idx,1], color='blue', label='1.125-2.125')\n",
    "    plt.scatter(tsne_2comp_data[T_late_idx,0], tsne_2comp_data[T_late_idx,1], color='orange', label='2.625-4.125')\n",
    "    plt.scatter(tsne_2comp_data[T_at_end_idx,0], tsne_2comp_data[T_at_end_idx,1], color='red', \\\n",
    "                label='at end (4.625)')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Component 0')\n",
    "    plt.ylabel('Component 1')\n",
    "    plt.title('2-component t-SNE (colored by ' + outcome + ')')\n",
    "    plt.savefig('tSNE_2comp_' + outcome + '.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 14})\n",
    "for outcome in outcomes:\n",
    "    T_early_idx = np.nonzero(np.where(pd_surv_df_atleast_i[outcome + '_T_atleast4.125']<1, 1, 0))[0]\n",
    "    T_middle_idx = np.nonzero(np.where(np.logical_and(pd_surv_df_atleast_i[outcome + '_T_atleast4.125']>=1, \\\n",
    "                                                      pd_surv_df_atleast_i[outcome + '_T_atleast4.125']<2.5), \\\n",
    "                                       1, 0))[0]\n",
    "    T_late_idx = np.nonzero(np.where(np.logical_and(pd_surv_df_atleast_i[outcome + '_T_atleast4.125']>=2.5, \\\n",
    "                                                    pd_surv_df_atleast_i[outcome + '_T_atleast4.125']<4.5), 1, 0))[0]\n",
    "    T_at_end_idx = np.nonzero(np.where(pd_surv_df_atleast_i[outcome + '_T_atleast4.125']==4.625, 1, 0))[0]\n",
    "    assert len(T_early_idx) + len(T_middle_idx) + len(T_late_idx) + len(T_at_end_idx) == len(pd_surv_df_atleast_i)\n",
    "    plt.scatter(tsne_1comp_data[T_early_idx,0], np.random.sample(size=len(T_early_idx)), color='green', \\\n",
    "                label='0-0.875')\n",
    "    plt.scatter(tsne_1comp_data[T_middle_idx,0], np.random.sample(size=len(T_middle_idx)), color='blue', \\\n",
    "                label='1.125-2.125')\n",
    "    plt.scatter(tsne_1comp_data[T_late_idx,0], np.random.sample(size=len(T_late_idx)), color='orange', \\\n",
    "                label='2.625-4.125')\n",
    "    plt.scatter(tsne_1comp_data[T_at_end_idx,0], np.random.sample(size=len(T_at_end_idx)), color='red', \\\n",
    "                label='at end (4.625)')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Component 0')\n",
    "    plt.ylabel('Random offset')\n",
    "    plt.title('1-component t-SNE (colored by ' + outcome + ')')\n",
    "    plt.savefig('tSNE_1comp_' + outcome + '.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_totals_df.EVENT_ID_DUR.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_ts = [0., 0.125, 0.375, 0.625, 0.875, 1.125, 1.625, 2.125, 2.625, 3.125, 3.625, 4.125, 4.625]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pairwise_plot(outcome_i, outcome_j):\n",
    "    pairwise_distribs = np.zeros((len(common_ts), len(common_ts)))\n",
    "    for t_i in range(pairwise_distribs.shape[0]):\n",
    "        for t_j in range(pairwise_distribs.shape[1]):\n",
    "            pairwise_distribs[t_i, t_j] \\\n",
    "                = len(pd_surv_df_atleast_i.loc[np.logical_and(pd_surv_df_atleast_i[outcome_i + '_T_atleast4.125']==common_ts[t_i], \\\n",
    "                                                              pd_surv_df_atleast_i[outcome_j + '_T_atleast4.125']==common_ts[t_j])])\n",
    "    pairwise_distribs_df = pd.DataFrame({outcome_i + '_T': common_ts})\n",
    "    for t_j in range(pairwise_distribs.shape[1]):\n",
    "        pairwise_distribs_df[common_ts[t_j]] = pairwise_distribs[:,t_j]\n",
    "    pairwise_distribs_df = pairwise_distribs_df.set_index(outcome_i + '_T')\n",
    "    fig, ax = plt.subplots(figsize=(10,8))\n",
    "    ax = heatmap(pairwise_distribs_df, vmin=0, vmax=100, annot=True, ax=ax)\n",
    "    ax.set_xlabel(outcome_j)\n",
    "    ax.set_ylabel(outcome_i)\n",
    "    plt.show()\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(outcomes)-1):\n",
    "    for j in range(i+1, len(outcomes)):\n",
    "        make_pairwise_plot(outcomes[i], outcomes[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot inertia against number of clusters in kmeans\n",
    "Inertia is the sum of squared distances from each sample to cluster center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patnos_enrolled_at_least_i_years \\\n",
    "    = set(second_to_last_visits_df.loc[second_to_last_visits_df['EVENT_ID_DUR']>=4.125].PATNO.values.tolist())\n",
    "pd_surv_df_atleast_i = pd_surv_df.loc[pd_surv_df['PATNO'].isin(patnos_enrolled_at_least_i_years)]\n",
    "outcome_T_atleast_i_cols = []\n",
    "for outcome in outcomes:\n",
    "    pd_surv_df_atleast_i[outcome + '_T_atleast' + str(4.125)] \\\n",
    "        = np.where(pd_surv_df_atleast_i[outcome + '_E']==0, 4.125 + 0.5, \\\n",
    "                   pd_surv_df_atleast_i[outcome + '_T']) # set censored to max time\n",
    "    pd_surv_df_atleast_i[outcome + '_T_atleast' + str(4.125)] \\\n",
    "        = np.where(pd_surv_df_atleast_i[outcome + '_T_atleast' + str(4.125)] >= 4.125 + 0.5, 4.125 + 0.5, \\\n",
    "                   pd_surv_df_atleast_i[outcome + '_T_atleast' + str(4.125)]) # set larger observed to max time\n",
    "    outcome_T_atleast_i_cols.append(outcome + '_T_atleast' + str(4.125))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_patnos = pd_surv_df_atleast_i.PATNO.values\n",
    "np.random.shuffle(all_patnos)\n",
    "train_test_cutoff = int(.85*len(all_patnos))\n",
    "train_patnos = set(all_patnos[:train_test_cutoff].tolist())\n",
    "test_patnos = set(all_patnos[train_test_cutoff:].tolist())\n",
    "train_df = pd_surv_df_atleast_i.loc[pd_surv_df_atleast_i['PATNO'].isin(train_patnos)]\n",
    "test_df = pd_surv_df_atleast_i.loc[pd_surv_df_atleast_i['PATNO'].isin(test_patnos)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inertias = []\n",
    "test_inertias = []\n",
    "max_n_clust = 50\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "for n_clust in range(1,max_n_clust):\n",
    "    kmeans = KMeans(n_clusters=n_clust, random_state=7)\n",
    "    kmeans.fit(train_df[outcome_T_atleast_i_cols])\n",
    "    train_inertias.append(kmeans.inertia_/len(train_df))\n",
    "    test_inertias.append(-1*kmeans.score(test_df[outcome_T_atleast_i_cols])/len(test_df))\n",
    "plt.plot(range(1,max_n_clust), train_inertias, label='train')\n",
    "plt.plot(range(1,max_n_clust), test_inertias, label='test')\n",
    "plt.legend()\n",
    "plt.xlabel('# clusters')\n",
    "plt.ylabel('Inertia per sample')\n",
    "plt.title('kmeans')\n",
    "plt.tight_layout()\n",
    "plt.savefig('kmeans_inertia_v_num_clust.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
