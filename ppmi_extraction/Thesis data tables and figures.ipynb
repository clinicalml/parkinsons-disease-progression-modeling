{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '../../../datasets/ppmi/visit_feature_inputs_asof_2019Jan24_using_CMEDTM/'\n",
    "treatment_dir = '../../../datasets/ppmi/treatment_pipeline_output_asof_2019Jan24/'\n",
    "raw_datadir = '../../../datasets/ppmi/raw_data_asof_2019Jan24/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treatment frequency table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_treatment_df = pd.read_csv(treatment_dir + 'PD_treatment_between_visits.csv')\n",
    "hc_treatment_df = pd.read_csv(treatment_dir + 'HC_treatment_between_visits.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_treatment_df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_groupings_list = ['Dopamine replacement', 'Muscle', 'Pain', 'Urinary', 'Anxiety', 'Depression', \\\n",
    "                            'Other psychiatric', 'Cognitive', 'Sleep', 'Digestive', 'Cardiovascular', \\\n",
    "                            'Anti-inflammatory', 'Immune', 'Respiratory', 'Thyroid', 'Supplement', 'Eye', 'Other']\n",
    "treatment_groupings = {'Dopamine replacement': ['DOPAMINE REPLACEMENT'], \\\n",
    "                       'Muscle': ['ANTICONVULSANT',  'ANTITREMOR',  'ANTISPASMODIC', 'MUSCLE RELAXER'], \\\n",
    "                       'Pain': ['ANESTHETIC',  'ANALGESIC'], \\\n",
    "                       'Urinary': ['BLADDER CONTROL'], \\\n",
    "                       'Anxiety': ['ANXIOLYTIC'], \\\n",
    "                       'Depression': ['ANTIDEPRESSANT'], \\\n",
    "                       'Other psychiatric': ['ANTIPSYCHOTIC',  'MOOD STABILIZER'], \\\n",
    "                       'Cognitive': ['COGNITIVE ENHANCER'], \\\n",
    "                       'Sleep': ['SLEEP AID'], \\\n",
    "                       'Digestive': ['ANTIEMETIC', 'ANTIDIARRHEAL', 'DIGESTIVE AID',  'ANTACID'], \\\n",
    "                       'Cardiovascular': ['ANTIHYPERTENSIVE', 'ANTIARRHYTHMIC',  'ANTIHYPOTENSIVE', \\\n",
    "                                          'ANTICOAGULANT/BLOOD THINNER'], \\\n",
    "                       'Anti-inflammatory': ['ANTIINFLAMMATORY',  'NSAID'], \\\n",
    "                       'Immune': ['IMMUNOSUPPRESSANT', 'ANTIHISTAMINE', 'ANTIVIRAL', 'ANTIBIOTIC', 'ANTIFUNGAL', \\\n",
    "                                  'ANTICANCER', 'VACCINE', 'ADRENALCORTICAL REPLACEMENT'], \\\n",
    "                       'Respiratory': ['DECONGESTANT', 'MUCOLYTIC',  'BRONCHODILATOR'], \\\n",
    "                       'Thyroid': ['THYROID', 'ANTITHYROID AGENT', 'THYROID HORMONE'], \\\n",
    "                       'Supplement': ['SUPPLEMENT',  'PD SUPPLEMENT', 'BONE/JOINT HEALTH'], \\\n",
    "                       'Eye': ['OPTHALAMIC', 'ANTIGLAUCOMA'], \\\n",
    "                       'Other': ['CONTRACEPTIVE', 'ANTI BPH', 'NEUROTOXIN', 'DERMATOLOGIC', 'STIMULANT', \\\n",
    "                                 'HORMONE REPLACEMENT', 'URIC ACID REDUCER', 'OTHER']}\n",
    "assert set(treatment_groupings_list) == set(treatment_groupings.keys())\n",
    "pd_num_patnos = float(pd_treatment_df.PATNO.nunique())\n",
    "hc_num_patnos = float(hc_treatment_df.PATNO.nunique())\n",
    "for grouping in treatment_groupings_list:\n",
    "    pd_treatment_df[grouping] = pd_treatment_df[treatment_groupings[grouping]].sum(axis=1)\n",
    "    hc_treatment_df[grouping] = hc_treatment_df[treatment_groupings[grouping]].sum(axis=1)\n",
    "    pd_grouping_num_patnos = pd_treatment_df.loc[pd_treatment_df[grouping] > 0].PATNO.nunique()\n",
    "    hc_grouping_num_patnos = hc_treatment_df.loc[hc_treatment_df[grouping] > 0].PATNO.nunique()\n",
    "    print(grouping + ': PD: ' + '{0:.3f}'.format(pd_grouping_num_patnos/pd_num_patnos) \\\n",
    "          + ', HC: ' + '{0:.3f}'.format(hc_grouping_num_patnos/hc_num_patnos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MDS-UPDRS treatment initiation + venn diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_totals_df = pd.read_csv(datadir + 'PD_totals_across_time.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nupdrs3_treated_df = pd_totals_df[['PATNO','EVENT_ID_DUR','NUPDRS3_on','NUPDRS3_off',\\\n",
    "                                   'NUPDRS3_maob']].dropna(subset=['NUPDRS3_on','NUPDRS3_off','NUPDRS3_maob'], \\\n",
    "                                                           how='all')\n",
    "nupdrs3_treated_df = nupdrs3_treated_df.sort_values(by=['EVENT_ID_DUR'])\n",
    "nupdrs3_first_treated_df = nupdrs3_treated_df.drop_duplicates(subset=['PATNO'], keep='first')\n",
    "print(nupdrs3_first_treated_df.EVENT_ID_DUR.mean())\n",
    "print(nupdrs3_first_treated_df.EVENT_ID_DUR.std())\n",
    "print(len(nupdrs3_first_treated_df.loc[nupdrs3_first_treated_df['EVENT_ID_DUR']<=1]))\n",
    "print(len(nupdrs3_first_treated_df.loc[nupdrs3_first_treated_df['EVENT_ID_DUR']>1]))\n",
    "nupdrs3_first_treated_df.EVENT_ID_DUR.plot.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_mdsupdrs3_df = pd.read_csv(raw_datadir + 'MDS_UPDRS_Part_III.csv')\n",
    "raw_mdsupdrs3_df = raw_mdsupdrs3_df.loc[raw_mdsupdrs3_df['PATNO'].isin(set(pd_totals_df.PATNO.unique().tolist()))]\n",
    "raw_mdsupdrs3_df = raw_mdsupdrs3_df.drop_duplicates(subset=['PATNO','EVENT_ID'])\n",
    "raw_mdsupdrs3_df.PD_MED_USE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib_venn import venn3\n",
    "# 1: levodopa, 2: dopamine agonist, 3: MAO-B, 4: 1 + 3, 5: 1 + 2, 6: 2 + 3, 7: 1 + 2 + 3\n",
    "#(Abc, aBc, ABc, abC, AbC, aBC, ABC)\n",
    "venn3(subsets=(1169, 449, 326, 446, 367, 264, 248), set_labels=('Levodopa', 'Dopamine agonist', 'MAO-B inhibitors'))\n",
    "#plt.show()\n",
    "plt.savefig('mdsupdrs3_treatment_venn.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline and year 3 stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohorts = ['PD','HC','PRODROMA','GENPD','GENUN','REGPD','REGUN','SWEDD']\n",
    "for cohort in cohorts:\n",
    "    cohort_totals_df = pd.read_csv(datadir + cohort + '_totals_across_time.csv')\n",
    "    cohort_totals_df['QUIP'] = np.where(cohort_totals_df['QUIP']>0, 1, 0)\n",
    "    cohort_totals_df['STAI'] = np.where(np.logical_and(~pd.isnull(cohort_totals_df['STATE_ANXIETY']), \\\n",
    "                                                       ~pd.isnull(cohort_totals_df['TRAIT_ANXIETY'])), \\\n",
    "                                        cohort_totals_df[['STATE_ANXIETY','TRAIT_ANXIETY']].sum(axis=1), float('NaN'))\n",
    "    sc_df = cohort_totals_df.loc[cohort_totals_df['EVENT_ID_DUR']==0]\n",
    "    bl_df = cohort_totals_df.loc[cohort_totals_df['EVENT_ID_DUR']==0.125]\n",
    "    sc_df \\\n",
    "        = sc_df[['PATNO','GDSSHORT','QUIP','STAI']].merge(bl_df[['PATNO','GDSSHORT','QUIP','STAI']], on=['PATNO'], \\\n",
    "                                                          suffixes=['_sc','_bl'], how='outer', validate='one_to_one')\n",
    "    bl_df = sc_df[['PATNO','GDSSHORT_bl','QUIP_bl','STAI_bl']]\n",
    "    bl_df.rename(columns={'GDSSHORT_bl': 'GDSSHORT', 'QUIP_bl': 'QUIP', 'STAI_bl': 'STAI'}, inplace=True)\n",
    "    sc_df = sc_df[['PATNO','GDSSHORT_sc','QUIP_sc','STAI_sc']]\n",
    "    sc_df.rename(columns={'GDSSHORT_sc': 'GDSSHORT', 'QUIP_sc': 'QUIP', 'STAI_sc': 'STAI'}, inplace=True)\n",
    "    sc_df.update(bl_df, overwrite=False)\n",
    "    yr3_df = cohort_totals_df.loc[cohort_totals_df['EVENT_ID_DUR']==3.125]\n",
    "    print(cohort)\n",
    "    print('GDS: {0:.4f}'.format(np.nanmean(sc_df['GDSSHORT'].values)) \\\n",
    "          + ', {0:.4f}, '.format(np.nanmean(yr3_df['GDSSHORT'].values)) \\\n",
    "          + str(len(sc_df['GDSSHORT'].dropna())) + ', ' + str(len(yr3_df['GDSSHORT'].dropna())))\n",
    "    print('QUIP: {0:.4f}'.format(np.nanmean(sc_df['QUIP'].values)) \\\n",
    "          + ', {0:.4f}, '.format(np.nanmean(yr3_df['QUIP'].values)) \\\n",
    "          + str(len(sc_df['QUIP'].dropna())) + ', ' + str(len(yr3_df['QUIP'].dropna())))\n",
    "    print('STAI: {0:.4f}'.format(np.nanmean(sc_df['STAI'].values)) \\\n",
    "          + ' ({0:.4f})'.format(np.nanstd(sc_df['STAI'].values)) \\\n",
    "          + ', {0:.4f}'.format(np.nanmean(yr3_df['STAI'].values)) \\\n",
    "          +' ({0:.4f}), '.format(np.nanstd(yr3_df['STAI'].values)) \\\n",
    "          + str(len(sc_df['STAI'].dropna())) + ', ' + str(len(yr3_df['STAI'].dropna())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_other_df = pd.read_csv(datadir + 'PD_other_across_time.csv')\n",
    "pd_other_df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_other_df.COGSTATE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohorts = ['PD','HC','PRODROMA','GENPD','GENUN','REGPD','REGUN','SWEDD']\n",
    "for cohort in cohorts:\n",
    "    cohort_totals_df = pd.read_csv(datadir + cohort + '_totals_across_time.csv')\n",
    "    sc_totals_df = cohort_totals_df.loc[cohort_totals_df['EVENT_ID_DUR']==0]\n",
    "    bl_totals_df = cohort_totals_df.loc[cohort_totals_df['EVENT_ID_DUR']==0.125]\n",
    "    cog_cols = ['HVLT_retent', 'HVLT_discrim_recog', 'HVLT_immed_recall', 'LNS', 'BJLO', 'SEMANTIC_FLUENCY']\n",
    "    sc_totals_df \\\n",
    "        = sc_totals_df[['PATNO']+cog_cols].merge(bl_totals_df[['PATNO']+cog_cols], on=['PATNO'], \\\n",
    "                                                 suffixes=['_sc','_bl'], how='outer', validate='one_to_one')\n",
    "    cog_bl_cols = []\n",
    "    cog_bl_cols_dict = dict()\n",
    "    cog_sc_cols = []\n",
    "    cog_sc_cols_dict = dict()\n",
    "    for col in cog_cols:\n",
    "        cog_bl_cols.append(col + '_bl')\n",
    "        cog_bl_cols_dict[col + '_bl'] = col\n",
    "        cog_sc_cols.append(col + '_sc')\n",
    "        cog_sc_cols_dict[col + '_sc'] = col\n",
    "    bl_totals_df = sc_totals_df[['PATNO']+cog_bl_cols]\n",
    "    bl_totals_df.rename(columns=cog_bl_cols_dict, inplace=True)\n",
    "    sc_totals_df = sc_totals_df[['PATNO']+cog_sc_cols]\n",
    "    sc_totals_df.rename(columns=cog_sc_cols_dict, inplace=True)\n",
    "    sc_totals_df.update(bl_totals_df, overwrite=False)\n",
    "    cohort_other_df = pd.read_csv(datadir + cohort + '_other_across_time.csv')\n",
    "    cohort_other_df['MCI_dementia'] = np.where(cohort_other_df['COGSTATE']>1, 1, 0)\n",
    "    sc_other_df = cohort_other_df.loc[cohort_other_df['EVENT_ID_DUR']==0]\n",
    "    bl_other_df = cohort_other_df.loc[cohort_other_df['EVENT_ID_DUR']==0.125]\n",
    "    sc_other_df \\\n",
    "        = sc_other_df[['PATNO','MCI_dementia','DVT_SDM']].merge(bl_other_df[['PATNO','MCI_dementia','DVT_SDM']], \\\n",
    "                                                                on=['PATNO'], how='outer', validate='one_to_one', \\\n",
    "                                                                suffixes=['_sc','_bl'])\n",
    "    bl_other_df = sc_other_df[['PATNO','MCI_dementia_bl','DVT_SDM_bl']]\n",
    "    bl_other_df.rename(columns={'MCI_dementia_bl':'MCI_dementia', 'DVT_SDM_bl':'DVT_SDM'}, inplace=True)\n",
    "    sc_other_df = sc_other_df[['PATNO','MCI_dementia_sc','DVT_SDM_sc']]\n",
    "    sc_other_df.rename(columns={'MCI_dementia_sc':'MCI_dementia', 'DVT_SDM_sc':'DVT_SDM'}, inplace=True)\n",
    "    sc_other_df.update(bl_other_df, overwrite=False)\n",
    "    print(cohort)\n",
    "    for col in cog_cols:\n",
    "        print(col + ': {0:.4f}'.format(np.nanmean(sc_totals_df[col].values)) \\\n",
    "              + ' ({0:.4f}), '.format(np.nanstd(sc_totals_df[col].values)) \\\n",
    "              + str(len(sc_totals_df[col].dropna())))\n",
    "    print('MCI_dementia: {0:.4f}'.format(np.nanmean(sc_other_df['MCI_dementia'].values)) \\\n",
    "          + ' ({0:.4f}), '.format(np.nanstd(sc_other_df['MCI_dementia'].values)) \\\n",
    "          + str(len(sc_other_df['MCI_dementia'].dropna())))\n",
    "    print('DVT_SDM: {0:.4f}'.format(np.nanmean(sc_other_df['DVT_SDM'].values)) \\\n",
    "          + ' ({0:.4f})'.format(np.nanstd(sc_other_df['DVT_SDM'].values)) \\\n",
    "          + str(len(sc_other_df['DVT_SDM'].dropna())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohorts = ['PD','HC','PRODROMA','GENPD','GENUN','REGPD','REGUN','SWEDD']\n",
    "for cohort in cohorts:\n",
    "    cohort_baseline_df = pd.read_csv(datadir + cohort + '_baseline.csv')\n",
    "    print(cohort + ': {0:.4f}'.format(np.nanmean(cohort_baseline_df.UPSIT.values)) \\\n",
    "          + ' ({0:.4f}), '.format(np.nanstd(cohort_baseline_df.UPSIT.values)) \\\n",
    "          + str(len(cohort_baseline_df.dropna(subset=['UPSIT']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_totals_df = pd.read_csv(datadir + 'PD_totals_across_time.csv')\n",
    "print(pd_totals_df.EPWORTH.value_counts())\n",
    "print(pd_totals_df.REMSLEEP.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohorts = ['PD','HC','PRODROMA','GENPD','GENUN','REGPD','REGUN','SWEDD']\n",
    "for cohort in cohorts:\n",
    "    cohort_totals_df = pd.read_csv(datadir + cohort + '_totals_across_time.csv')\n",
    "    sc_df = cohort_totals_df.loc[cohort_totals_df['EVENT_ID_DUR']==0]\n",
    "    bl_df = cohort_totals_df.loc[cohort_totals_df['EVENT_ID_DUR']==0.125]\n",
    "    sc_df \\\n",
    "        = sc_df[['PATNO','SCOPA-AUT','REMSLEEP','EPWORTH']].merge(bl_df[['PATNO','SCOPA-AUT','REMSLEEP','EPWORTH']], \\\n",
    "                                                                  on=['PATNO'], suffixes=['_sc','_bl'], how='outer', \\\n",
    "                                                                  validate='one_to_one')\n",
    "    bl_df = sc_df[['PATNO','SCOPA-AUT_bl','REMSLEEP_bl','EPWORTH_bl']]\n",
    "    bl_df.rename(columns={'SCOPA-AUT_bl': 'SCOPA-AUT', 'REMSLEEP_bl': 'REMSLEEP', 'EPWORTH_bl': 'EPWORTH'}, \\\n",
    "                 inplace=True)\n",
    "    sc_df = sc_df[['PATNO','SCOPA-AUT_sc','REMSLEEP_sc','EPWORTH_sc']]\n",
    "    sc_df.rename(columns={'SCOPA-AUT_sc': 'SCOPA-AUT', 'REMSLEEP_sc': 'REMSLEEP', 'EPWORTH_sc': 'EPWORTH'}, \\\n",
    "                 inplace=True)\n",
    "    sc_df.update(bl_df, overwrite=False)\n",
    "    yr3_df = cohort_totals_df.loc[cohort_totals_df['EVENT_ID_DUR']==3.125]\n",
    "    print(cohort)\n",
    "    print('SCOPA-AUT: {0:.4f}'.format(np.nanmean(sc_df['SCOPA-AUT'].values)) \\\n",
    "          + ' ({0:.4f})'.format(np.nanstd(sc_df['SCOPA-AUT'].values)) \\\n",
    "          + ', {0:.4f}'.format(np.nanmean(yr3_df['SCOPA-AUT'].values)) \\\n",
    "          +' ({0:.4f}), '.format(np.nanstd(yr3_df['SCOPA-AUT'].values)) \\\n",
    "          + str(len(sc_df['SCOPA-AUT'].dropna())) + ', ' + str(len(yr3_df['SCOPA-AUT'].dropna())))\n",
    "    print('EPWORTH: {0:.4f}'.format(np.nanmean(sc_df['EPWORTH'].values)) \\\n",
    "          + ', {0:.4f}, '.format(np.nanmean(yr3_df['EPWORTH'].values)) \\\n",
    "          + str(len(sc_df['EPWORTH'].dropna())) + ', ' + str(len(yr3_df['EPWORTH'].dropna())))\n",
    "    print('REMSLEEP: {0:.4f}'.format(np.nanmean(sc_df['REMSLEEP'].values)) \\\n",
    "          + ', {0:.4f}, '.format(np.nanmean(yr3_df['REMSLEEP'].values)) \\\n",
    "          + str(len(sc_df['SCOPA-AUT'].dropna())) + ', ' + str(len(yr3_df['GDSSHORT'].dropna())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_baseline_df = pd.read_csv(datadir + 'PD_baseline.csv')\n",
    "pd_baseline_df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: baseline features (table 1.1)\n",
    "cohorts = ['PD','HC','PRODROMA','GENPD','GENUN','REGPD','REGUN','SWEDD']\n",
    "for cohort in cohorts:\n",
    "    cohort_baseline_df = pd.read_csv(datadir + cohort + '_baseline.csv')\n",
    "    cohort_baseline_df['FAMHIST'] \\\n",
    "        = np.where(cohort_baseline_df[['BIOMOMPD','BIODADPD','PATAUPD','KIDSPD']].sum(axis=1) > 0, 1, 0)\n",
    "    print(cohort)\n",
    "    print('Male: {0:.3f}'.format(np.nanmean(cohort_baseline_df.MALE.values)))\n",
    "    print('White: {0:.3f}'.format(np.nanmean(cohort_baseline_df.RAWHITE.values)))\n",
    "    print('Fam hist: {0:.3f}'.format(np.nanmean(cohort_baseline_df.FAMHIST.values)))\n",
    "    print('Time since diag: {0:.3f}'.format(np.nanmean(cohort_baseline_df.DIS_DUR_BY_CONSENTDT.values)) \\\n",
    "          + ' ({0:.3f}), '.format(np.nanstd(cohort_baseline_df.DIS_DUR_BY_CONSENTDT.values)) \\\n",
    "          + str(len(cohort_baseline_df['DIS_DUR_BY_CONSENTDT'].dropna())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohorts = ['PD','HC','PRODROMA','GENPD','GENUN','REGPD','REGUN','SWEDD']\n",
    "for cohort in cohorts:\n",
    "    cohort_other_df = pd.read_csv(datadir + cohort + '_other_across_time.csv')\n",
    "    sc_df = cohort_other_df.loc[cohort_other_df['EVENT_ID_DUR']==0]\n",
    "    bl_df = cohort_other_df.loc[cohort_other_df['EVENT_ID_DUR']==0.125]\n",
    "    sc_df = sc_df[['PATNO','AGE']].merge(bl_df[['PATNO','AGE']], on=['PATNO'], suffixes=['_sc','_bl'], how='outer', \\\n",
    "                                         validate='one_to_one')\n",
    "    bl_df = sc_df[['PATNO','AGE_bl']]\n",
    "    bl_df.rename(columns={'AGE_bl': 'AGE'}, inplace=True)\n",
    "    sc_df = sc_df[['PATNO','AGE_sc']]\n",
    "    sc_df.rename(columns={'AGE_sc': 'AGE'}, inplace=True)\n",
    "    sc_df.update(bl_df, overwrite=False)\n",
    "    print(cohort)\n",
    "    print('AGE: {0:.4f}'.format(np.nanmean(sc_df['AGE'].values)) \\\n",
    "          + ' ({0:.4f})'.format(np.nanstd(sc_df['AGE'].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohorts = ['PD','HC','PRODROMA','GENPD','GENUN','REGPD','REGUN','SWEDD']\n",
    "print('Num visits')\n",
    "for cohort in cohorts:\n",
    "    cohort_totals_df = pd.read_csv(datadir + cohort + '_totals_across_time.csv')\n",
    "    cohort_totals_df = cohort_totals_df.dropna(subset=['NUPDRS2'])\n",
    "    num_visits = []\n",
    "    for patno in cohort_totals_df.PATNO.unique():\n",
    "        num_visits.append(len(cohort_totals_df.loc[cohort_totals_df['PATNO']==patno]))\n",
    "    print(cohort + ': {0:.4f}'.format(np.nanmean(np.array(num_visits))) \\\n",
    "          + ' ({0:.4f})'.format(np.nanstd(np.array(num_visits))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohorts = ['PD','HC','PRODROMA','GENPD','GENUN','REGPD','REGUN','SWEDD']\n",
    "print('Enroll time')\n",
    "for cohort in cohorts:\n",
    "    cohort_totals_df = pd.read_csv(datadir + cohort + '_totals_across_time.csv')\n",
    "    cohort_totals_df = cohort_totals_df.sort_values(by=['EVENT_ID_DUR'])\n",
    "    cohort_totals_df = cohort_totals_df.drop_duplicates(subset=['PATNO'], keep='last')\n",
    "    print(cohort + ': {0:.4f}'.format(np.nanmean(cohort_totals_df.EVENT_ID_DUR.values)) \\\n",
    "          + ' ({0:.4f})'.format(np.nanstd(cohort_totals_df.EVENT_ID_DUR.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_other_df = pd.read_csv(datadir + 'PD_other_across_time.csv')\n",
    "td_pigd_cols = []\n",
    "for col in pd_other_df.columns:\n",
    "    if col.startswith('TD_PIGD'):\n",
    "        td_pigd_cols.append(col)\n",
    "td_pigd_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_other_df = pd_other_df.loc[pd_other_df['EVENT_ID_DUR']==0]\n",
    "yr3_other_df = pd_other_df.loc[pd_other_df['EVENT_ID_DUR']==3.125]\n",
    "sc_td_count = len(sc_other_df.loc[sc_other_df['TD_PIGD_untreated:tremor']==1])\n",
    "sc_pigd_count = len(sc_other_df.loc[sc_other_df['TD_PIGD_untreated:posture']==1])\n",
    "sc_indet_count = len(sc_other_df.loc[sc_other_df['TD_PIGD_untreated:indet']==1])\n",
    "sc_total_count = float(sc_td_count + sc_pigd_count + sc_indet_count)\n",
    "print(sc_td_count/sc_total_count, sc_pigd_count/sc_total_count)\n",
    "tremor_cols = []\n",
    "posture_cols = []\n",
    "for col in td_pigd_cols:\n",
    "    if col.endswith('tremor'):\n",
    "        tremor_cols.append(col)\n",
    "    elif col.endswith('posture'):\n",
    "        posture_cols.append(col)\n",
    "yr3_other_df = yr3_other_df.dropna(subset=td_pigd_cols, how='all')\n",
    "yr3_other_df['TD_PIGD:tremor'] = np.where(np.nansum(yr3_other_df[tremor_cols].values, axis=1)>0, 1, 0)\n",
    "yr3_other_df['TD_PIGD:posture'] = np.where(np.nansum(yr3_other_df[posture_cols].values, axis=1)>0, 1, 0)\n",
    "yr3_other_df['TD_PIGD:both'] = np.where(yr3_other_df[['TD_PIGD:tremor','TD_PIGD:posture']].sum(axis=1)==2,1,0)\n",
    "print(yr3_other_df['TD_PIGD:tremor'].mean(), yr3_other_df['TD_PIGD:posture'].mean(), \\\n",
    "      yr3_other_df['TD_PIGD:both'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohorts = ['PD','HC','PRODROMA','GENPD','GENUN','REGPD','REGUN','SWEDD']\n",
    "state_anxiety = []\n",
    "trait_anxiety = []\n",
    "for cohort in cohorts:\n",
    "    cohort_totals_df = pd.read_csv(datadir + cohort + '_totals_across_time.csv')\n",
    "    cohort_totals_df = cohort_totals_df.dropna(subset=['STATE_ANXIETY','TRAIT_ANXIETY'])\n",
    "    state_anxiety += cohort_totals_df.STATE_ANXIETY.values.tolist()\n",
    "    trait_anxiety += cohort_totals_df.TRAIT_ANXIETY.values.tolist()\n",
    "from scipy.stats import pearsonr\n",
    "print(pearsonr(state_anxiety, trait_anxiety))\n",
    "plt.scatter(state_anxiety, trait_anxiety)\n",
    "plt.rcParams.update({'font.size':18})\n",
    "plt.xlabel('State anxiety')\n",
    "plt.ylabel('Trait anxiety')\n",
    "plt.savefig('state_trait_anxiety_corr.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohorts = ['PD','HC','PRODROMA','GENPD','GENUN','REGPD','REGUN','SWEDD']\n",
    "state_anxiety_min = 0\n",
    "state_anxiety_max = 0\n",
    "trait_anxiety_min = 0\n",
    "trait_anxiety_max = 0\n",
    "for cohort in cohorts:\n",
    "    cohort_totals_df = pd.read_csv(datadir + cohort + '_totals_across_time.csv')\n",
    "    cohort_totals_df = cohort_totals_df.dropna(subset=['STATE_ANXIETY','TRAIT_ANXIETY'])\n",
    "    cohort_state_max = cohort_totals_df.STATE_ANXIETY.max()\n",
    "    cohort_state_min = cohort_totals_df.STATE_ANXIETY.min()\n",
    "    cohort_trait_max = cohort_totals_df.TRAIT_ANXIETY.max()\n",
    "    cohort_trait_min = cohort_totals_df.TRAIT_ANXIETY.min()\n",
    "    if cohort_state_max > state_anxiety_max:\n",
    "        state_anxiety_max = cohort_state_max\n",
    "    if cohort_trait_max > trait_anxiety_max:\n",
    "        trait_anxiety_max = cohort_trait_max\n",
    "    if cohort_state_min < state_anxiety_min:\n",
    "        state_anxiety_min = cohort_state_min\n",
    "    if cohort_trait_min < trait_anxiety_min:\n",
    "        trait_anxiety_min = cohort_trait_min\n",
    "state_trait_arr = np.zeros((int(state_anxiety_max - state_anxiety_min + 1), \\\n",
    "                            int(trait_anxiety_max - trait_anxiety_min + 1)))\n",
    "for cohort in cohorts:\n",
    "    cohort_totals_df = pd.read_csv(datadir + cohort + '_totals_across_time.csv')\n",
    "    cohort_totals_df = cohort_totals_df.dropna(subset=['STATE_ANXIETY','TRAIT_ANXIETY'])\n",
    "    state_arr = cohort_totals_df.STATE_ANXIETY.values.astype(np.int)\n",
    "    trait_arr = cohort_totals_df.TRAIT_ANXIETY.values.astype(np.int)\n",
    "    for idx in range(len(state_arr)):\n",
    "        state_idx = state_arr[idx] - state_anxiety_min\n",
    "        trait_idx = trait_arr[idx] - trait_anxiety_min\n",
    "        state_trait_arr[state_idx, trait_idx] += 1\n",
    "state_trait_arr_df = pd.DataFrame({'index': np.arange(state_anxiety_min, state_anxiety_max+1)})\n",
    "for trait_idx in range(state_trait_arr.shape[1]):\n",
    "    state_trait_arr_df[trait_anxiety_min + trait_idx] = state_trait_arr[:,trait_idx]\n",
    "state_trait_arr_df.set_index('index', inplace=True)\n",
    "from seaborn import heatmap\n",
    "plt.rcParams.update({'font.size':14})\n",
    "heatmap(state_trait_arr_df)\n",
    "plt.ylabel('State anxiety')\n",
    "plt.xlabel('Trait anxiety')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prodromal diagnoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prodromal_other_df = pd.read_csv(datadir + 'PRODROMA_other_across_time.csv')\n",
    "prodromal_other_df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prodromal_diag_cols = []\n",
    "for col in prodromal_other_df.columns:\n",
    "    if col.startswith('PRODROMAL_DIAG:'):\n",
    "        prodromal_diag_cols.append(col)\n",
    "prodromal_diag_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenoconv_patnos = prodromal_other_df.loc[prodromal_other_df['PRODROMAL_DIAG:PHENOCONV']==1].PATNO.unique()\n",
    "motor_patnos = prodromal_other_df.loc[prodromal_other_df['PRODROMAL_DIAG:MOTOR_PRODROMA']==1].PATNO.unique()\n",
    "nonmotor_patnos = prodromal_other_df.loc[prodromal_other_df['PRODROMAL_DIAG:NONMOTOR_PRODROMA']==1].PATNO.unique()\n",
    "no_neuro_patnos = prodromal_other_df.loc[prodromal_other_df['PRODROMAL_DIAG:NO_NEURO']==1].PATNO.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(phenoconv_patnos)\n",
    "print(motor_patnos)\n",
    "print(nonmotor_patnos)\n",
    "print(no_neuro_patnos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_patno_prodromal_diags(patno1):\n",
    "    patno1_df = prodromal_other_df.loc[prodromal_other_df['PATNO']==patno1]\n",
    "    patno1_df = patno1_df.loc[np.nansum(patno1_df[prodromal_diag_cols], axis=1)>0]\n",
    "    patno1_df = patno1_df.sort_values(by=['EVENT_ID_DUR'])\n",
    "    patno1_df['PRODROMAL_DIAG'] = 'None'\n",
    "    patno1_df['PRODROMAL_DIAG'] = np.where(patno1_df['PRODROMAL_DIAG:NO_NEURO']==1, 'NO_NEURO', \\\n",
    "                                           patno1_df['PRODROMAL_DIAG'])\n",
    "    patno1_df['PRODROMAL_DIAG'] = np.where(patno1_df['PRODROMAL_DIAG:PHENOCONV']==1, 'PHENOCONV', \\\n",
    "                                           patno1_df['PRODROMAL_DIAG'])\n",
    "    patno1_df['PRODROMAL_DIAG'] = np.where(patno1_df['PRODROMAL_DIAG:MOTOR_PRODROMA']==1, 'MOTOR_PRODROMA', \\\n",
    "                                           patno1_df['PRODROMAL_DIAG'])\n",
    "    patno1_df['PRODROMAL_DIAG'] = np.where(patno1_df['PRODROMAL_DIAG:NONMOTOR_PRODROMA']==1, 'NONMOTOR_PRODROMA', \\\n",
    "                                           patno1_df['PRODROMAL_DIAG'])\n",
    "    display(patno1_df[['EVENT_ID_DUR','PRODROMAL_DIAG']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(28037)\n",
    "np.random.shuffle(phenoconv_patnos)\n",
    "np.random.shuffle(nonmotor_patnos)\n",
    "np.random.shuffle(motor_patnos)\n",
    "np.random.shuffle(no_neuro_patnos)\n",
    "for idx in range(5):\n",
    "    patno = phenoconv_patnos[idx]\n",
    "    print(patno)\n",
    "    display_patno_prodromal_diags(patno)\n",
    "    patno = nonmotor_patnos[idx]\n",
    "    print(patno)\n",
    "    display_patno_prodromal_diags(patno)\n",
    "    patno = motor_patnos[idx]\n",
    "    print(patno)\n",
    "    display_patno_prodromal_diags(patno)\n",
    "    patno = no_neuro_patnos[idx]\n",
    "    print(patno)\n",
    "    display_patno_prodromal_diags(patno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversion patterns\n",
    "diag_seq_counts = dict()\n",
    "for patno in prodromal_other_df.PATNO.unique():\n",
    "    patno_df = prodromal_other_df.loc[prodromal_other_df['PATNO']==patno]\n",
    "    patno_df = patno_df.loc[np.nansum(patno_df[prodromal_diag_cols], axis=1)>0]\n",
    "    patno_df = patno_df.sort_values(by=['EVENT_ID_DUR'])\n",
    "    patno_df['PRODROMAL_DIAG'] = 'None'\n",
    "    patno_df['PRODROMAL_DIAG'] = np.where(patno_df['PRODROMAL_DIAG:NO_NEURO']==1, 'NO_NEURO', \\\n",
    "                                          patno_df['PRODROMAL_DIAG'])\n",
    "    patno_df['PRODROMAL_DIAG'] = np.where(patno_df['PRODROMAL_DIAG:PHENOCONV']==1, 'PHENOCONV', \\\n",
    "                                          patno_df['PRODROMAL_DIAG'])\n",
    "    patno_df['PRODROMAL_DIAG'] = np.where(patno_df['PRODROMAL_DIAG:MOTOR_PRODROMA']==1, 'MOTOR_PRODROMA', \\\n",
    "                                          patno_df['PRODROMAL_DIAG'])\n",
    "    patno_df['PRODROMAL_DIAG'] = np.where(patno_df['PRODROMAL_DIAG:NONMOTOR_PRODROMA']==1, 'NONMOTOR_PRODROMA', \\\n",
    "                                          patno_df['PRODROMAL_DIAG'])\n",
    "    diag_vals = patno_df.PRODROMAL_DIAG.values\n",
    "    diag_seq = diag_vals[0]\n",
    "    prev_diag = diag_vals[0]\n",
    "    if len(diag_vals) > 1:\n",
    "        for diag_val in diag_vals[1:]:\n",
    "            if diag_val != prev_diag:\n",
    "                diag_seq += ', ' + diag_val\n",
    "                prev_diag = diag_val\n",
    "    if diag_seq in diag_seq_counts.keys():\n",
    "        diag_seq_counts[diag_seq] += 1\n",
    "    else:\n",
    "        diag_seq_counts[diag_seq] = 1\n",
    "diag_seq_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_phenoconv = 0\n",
    "has_phenoconv_then_something_else = 0\n",
    "for diag_seq in diag_seq_counts.keys():\n",
    "    if 'PHENOCONV' in diag_seq:\n",
    "        has_phenoconv += diag_seq_counts[diag_seq]\n",
    "        if 'PHENOCONV, ' in diag_seq:\n",
    "            has_phenoconv_then_something_else += diag_seq_counts[diag_seq]\n",
    "has_phenoconv, has_phenoconv_then_something_else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_no_neuro = 0\n",
    "for diag_seq in diag_seq_counts.keys():\n",
    "    if 'NO_NEURO' in diag_seq:\n",
    "        has_no_neuro += diag_seq_counts[diag_seq]\n",
    "has_no_neuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30 only nonmotor\n",
    "# 15 phenoconverted, 3 oscillated with something else\n",
    "# 11 nonmotor to motor without osccilate\n",
    "# 8 oscillate nonmotor and motor\n",
    "# 11 oscillate with no neuro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hoehn and Yahr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_datadir = '../../../datasets/ppmi/raw_data_asof_2019Jan24/'\n",
    "mds3_df = pd.read_csv(raw_datadir + 'MDS_UPDRS_Part_III.csv')\n",
    "mds3_df.NHY.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_datadir = '../../../datasets/ppmi/raw_data_asof_2019Jan24/'\n",
    "mds3_df = pd.read_csv(raw_datadir + 'MDS_UPDRS_Part_III.csv').dropna(subset=['NHY'])\n",
    "datadir = '../../../datasets/ppmi/visit_feature_inputs_asof_2019Jan24/'\n",
    "cohorts = ['PD','HC','PRODROMA','GENPD','GENUN','REGPD','REGUN','SWEDD']\n",
    "for cohort in cohorts:\n",
    "    cohort_patnos = pd.read_csv(datadir + cohort + '_totals_across_time.csv').PATNO.unique()\n",
    "    cohort_mds3_df = mds3_df.loc[mds3_df['PATNO'].isin(cohort_patnos)]\n",
    "    cohort_mds3_yr0_df = cohort_mds3_df.loc[cohort_mds3_df['EVENT_ID']=='SC']\n",
    "    cohort_mds3_yr0_df = cohort_mds3_yr0_df.drop_duplicates(subset=['PATNO'])\n",
    "    cohort_mds3_yr3_df = cohort_mds3_df.loc[cohort_mds3_df['EVENT_ID'].isin({'V12','PV12'})]\n",
    "    cohort_mds3_yr3_df = cohort_mds3_yr3_df.drop_duplicates(subset=['PATNO'])\n",
    "    num_patnos_yr0 = float(len(cohort_mds3_yr0_df))\n",
    "    num_patnos_yr3 = float(len(cohort_mds3_yr3_df))\n",
    "    yr0_output_str = cohort + ' at yr 0: ' + str(len(cohort_mds3_yr0_df))\n",
    "    if num_patnos_yr3 > 0:\n",
    "        yr3_output_str = cohort + ' at yr 3: ' + str(len(cohort_mds3_yr3_df))\n",
    "    for idx in range(6):\n",
    "        idx_freq_yr0 = len(cohort_mds3_yr0_df.loc[cohort_mds3_yr0_df['NHY']==idx])/num_patnos_yr0\n",
    "        yr0_output_str += ', {0:.4f}'.format(idx_freq_yr0)\n",
    "        if num_patnos_yr3 > 0:\n",
    "            idx_freq_yr3 = len(cohort_mds3_yr3_df.loc[cohort_mds3_yr3_df['NHY']==idx])/num_patnos_yr3\n",
    "            yr3_output_str += ', {0:.4f}'.format(idx_freq_yr3)\n",
    "    print(yr0_output_str)\n",
    "    if num_patnos_yr3 > 0:\n",
    "        print(yr3_output_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
