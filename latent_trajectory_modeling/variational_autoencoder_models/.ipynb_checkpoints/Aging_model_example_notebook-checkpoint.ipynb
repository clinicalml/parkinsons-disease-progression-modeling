{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.special import expit\n",
    "\n",
    "import variational_rate_of_aging_monotonic_autoencoder\n",
    "import variational_autoencoder\n",
    "import variational_longitudinal_monotonic_rate_of_aging_autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.append(\"../\")\n",
    "from DataLoaders.PPMI_loader import PPMI_loader\n",
    "from Evaluation.RankingEvaluator import RankingEvaluator\n",
    "from PostLatentModels.CorrelationCalculator import CorrelationCalculator\n",
    "from Evaluation.MeanSquaredErrorEvaluator import MeanSquaredErrorEvaluator\n",
    "from util_aging import *\n",
    "from Util.visualizer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_loader = PPMI_loader(\"../../PD_questions.csv\")  # change to path to file PD_questions.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####### most basic option, return dictionary of both df in aging format and normal format\n",
    "# data_dict = data_loader.extended_get_train_valid_test_split(train_valid_test_split=[70,10,20],\n",
    "#                                                 aging_format=True)\n",
    "\n",
    "\n",
    "####### sample data using linear interpolation of each score\n",
    "data_dict = data_loader.extended_get_train_valid_test_split(train_valid_test_split=[70,10,20],\n",
    "                                                aging_format=True,\n",
    "                                                fill_train_with_sample=50000)\n",
    "\n",
    "\n",
    "# ####### longitudinal data\n",
    "# data_dict = data_loader.extended_get_train_valid_test_split(train_valid_test_split=[70,10,20],\n",
    "#                                                 aging_format=True,\n",
    "#                                                 fill_train_with_sample=50000,\n",
    "#                                                 longitudinal=True,\n",
    "#                                                 longitudinal_length=10)\n",
    "\n",
    "\n",
    "# ####### sampled + longitudinal + 5-fold cross validation  # list of data_dict\n",
    "# data_dicts = data_loader.extended_get_train_valid_test_split(train_valid_test_split=[70,10,20],\n",
    "#                                                 aging_format=True,\n",
    "#                                                 fill_train_with_sample=50000,\n",
    "#                                                 longitudinal=True,\n",
    "#                                                 longitudinal_length=20,\n",
    "#                                                 fold=5,\n",
    "#                                                 valid_ratio=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model random seed is 7235\n",
      "initialization scaling is 0.100\n",
      "Weight constraint method is take_absolute_value\n",
      "Fitting model using method VariationalRateOfAgingMonotonicAutoencoder.\n",
      "Train size 51468; valid size 233\n",
      "Setting aging rate scaling factor to 0.100\n",
      "Added encoder layer for Z_age with input dimension 47 and output dimension 20\n",
      "Added encoder layer for Z_age with input dimension 20 and output dimension 1\n",
      "Added encoder layer for residual with input dimension 47 and output dimension 20\n",
      "Added encoder layer for residual with input dimension 20 and output dimension 0\n",
      "Added decoder layer for Z_age with input dimension 1 and output dimension 46\n",
      "Added decoder layer for residual with input dimension 0 and output dimension 46\n",
      "Deleting weight layer decoder_Z_age_h0 because unnecessary for monotonic autoencoder\n",
      "Deleting bias layer decoder_Z_age_b0 because unnecessary for monotonic autoencoder\n",
      "Adding monotonic linear layer with input dimension 1 and output dimension 46\n",
      "Adding nonlinearity post_linear_layer\n",
      "Epoch 0:\n",
      "Train: mean loss 49.460 (0.000 + 49.417 + 1.000 * 0.044).  Valid: mean loss 52.819 (0.000 + 52.781 + 1.000 * 0.038)\n",
      "Continuous variance is 0.506\n",
      "Epoch 10:\n",
      "Train: mean loss 49.438 (0.000 + 49.357 + 1.000 * 0.081).  Valid: mean loss 52.901 (0.000 + 52.841 + 1.000 * 0.060)\n",
      "Continuous variance is 0.504\n",
      "Warning! valid loss not decreasing this epoch\n",
      "Epoch 20:\n",
      "Train: mean loss 49.433 (0.000 + 49.336 + 1.000 * 0.097).  Valid: mean loss 52.881 (0.000 + 52.826 + 1.000 * 0.055)\n",
      "Continuous variance is 0.515\n",
      "Warning! valid loss not decreasing this epoch\n",
      "Epoch 30:\n",
      "Train: mean loss 49.402 (0.000 + 49.296 + 1.000 * 0.106).  Valid: mean loss 53.095 (0.000 + 53.041 + 1.000 * 0.054)\n",
      "Continuous variance is 0.501\n",
      "Warning! valid loss not decreasing this epoch\n",
      "Epoch 40:\n",
      "Train: mean loss 49.380 (0.000 + 49.260 + 1.000 * 0.120).  Valid: mean loss 52.920 (0.000 + 52.846 + 1.000 * 0.075)\n",
      "Continuous variance is 0.499\n",
      "Warning! valid loss not decreasing this epoch\n",
      "Epoch 50:\n",
      "Train: mean loss 49.406 (0.000 + 49.294 + 1.000 * 0.111).  Valid: mean loss 52.898 (0.000 + 52.814 + 1.000 * 0.084)\n",
      "Continuous variance is 0.503\n",
      "Warning! valid loss not decreasing this epoch\n",
      "Epoch 59:\n",
      "Train: mean loss 49.401 (0.000 + 49.281 + 1.000 * 0.120).  Valid: mean loss 52.884 (0.000 + 52.810 + 1.000 * 0.074)\n",
      "Continuous variance is 0.493\n",
      "Warning! valid loss not decreasing this epoch\n"
     ]
    }
   ],
   "source": [
    "# ######### vae model\n",
    "# model = variational_autoencoder.VariationalAutoencoder(\n",
    "#             encoder_layer_sizes=[20,10,1], \n",
    "#             decoder_layer_sizes=[10],\n",
    "#             max_epochs=100,\n",
    "#             random_seed=np.random.choice(range(10000)),)\n",
    "# model.fit(data_dict[\"aging_train_df\"], data_dict[\"aging_val_df\"], verbose=False)\n",
    "\n",
    "\n",
    "# ######### Aging cross sectional\n",
    "model = variational_rate_of_aging_monotonic_autoencoder.VariationalRateOfAgingMonotonicAutoencoder(\n",
    "                    encoder_layer_sizes=[20,1], \n",
    "                    decoder_layer_sizes=[], \n",
    "                    learn_continuous_variance=True,\n",
    "                    non_linearity='relu',\n",
    "                    k_age=1, \n",
    "                    max_epochs=60, \n",
    "                    learning_rate=0.01,\n",
    "                    preset_aging_rate_scaling_factor=0.1,\n",
    "                    polynomial_powers_to_fit = [0.2, 0.5, 1, 2, 3],\n",
    "                    random_seed=np.random.choice(range(10000)))\n",
    "model.fit(data_dict[\"aging_train_df\"], data_dict[\"aging_val_df\"], verbose=False)\n",
    "\n",
    "\n",
    "# ######### Aging Longitudinal  # data_dict must be generated with longitudinal option\n",
    "\n",
    "# model= variational_longitudinal_monotonic_rate_of_aging_autoencoder.VariationalLongitudinalMonotonicRateOfAgingAutoencoder(\n",
    "#                         encoder_layer_sizes=[20,10,1], \n",
    "#                         decoder_layer_sizes=[], \n",
    "#                         learn_continuous_variance=True,\n",
    "#                         non_linearity='relu',\n",
    "#                         k_age=1, \n",
    "#                         max_epochs=70, \n",
    "#                         learning_rate=0.01,\n",
    "#                         preset_aging_rate_scaling_factor=0.1,\n",
    "#                         polynomial_powers_to_fit = [0.2, 0.5, 1, 2, 3],\n",
    "#                         random_seed=np.random.choice(range(10000)))\n",
    "\n",
    "# model.fit(data_dict[\"aging_train_df\"], data_dict[\"aging_val_df\"], \n",
    "#                    train_lon_df0=data_dict[\"aging_train_lon_df0\"],\n",
    "#                    train_lon_df1=data_dict[\"aging_train_lon_df1\"],\n",
    "#                    verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(258, 60) (258,) (40, 60) (40,)\n",
      "0.1 [[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         1.22320428 0.        ]]\n",
      "0.5 [[ 5.67290004e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -1.12561572e-01  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -7.14452469e-01  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -9.38572669e-02 -2.76343927e-01  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  2.81206902e-03  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.16936847e-01\n",
      "   0.00000000e+00  2.61235440e+00  6.56038841e+00  0.00000000e+00]]\n",
      "1 [[ 0.1156293   0.          0.         -0.33861975  0.          0.\n",
      "  -1.18363049 -0.11145014  0.          0.75675282  0.09552866  0.\n",
      "   0.         -0.44090621 -0.03618847  0.          0.          0.\n",
      "   0.          0.          0.          0.         -0.14066152  0.\n",
      "   0.          0.         -1.26306517  0.          0.          0.\n",
      "   0.         -0.24965841  0.          0.          0.26665068  0.\n",
      "   0.          0.          0.          0.         -0.14288466 -0.91192841\n",
      "   0.          0.          0.          0.          0.          0.22761597\n",
      "   0.          0.04916072  0.07505803  0.          0.          0.\n",
      "   0.         -0.24084234  0.          3.35076435  8.36284314  0.1656789 ]]\n",
      "5 [[ 0.0385803   0.          0.27192781 -3.26240432 -0.27166765 -0.25433471\n",
      "  -1.82138673 -0.27340731  0.          3.01367708  0.76478255  0.\n",
      "  -0.44429532 -1.24133411 -0.34634605 -0.01508154  0.04751384  0.88075938\n",
      "  -0.08045603  0.         -0.8509178  -0.13380404 -1.94930091  0.84936503\n",
      "   1.09808814  1.61383254 -2.12749087  0.          0.94945635 -2.94633325\n",
      "   0.         -0.86043019  0.34628129  0.          2.36713511 -1.32287459\n",
      "   0.          0.          0.          0.         -0.28944727 -2.32178985\n",
      "   0.         -0.17632021  0.         -1.79521712 -0.73168064  2.00846492\n",
      "   0.          0.33042597  0.59233812 -1.38242326  0.43986119 -0.63464035\n",
      "   1.40078012 -0.27888475 -1.27644909  5.30344117 13.64042151  1.70263103]]\n",
      "10 [[ 0.07886303  0.08221283  0.37969429 -4.12556204 -0.31491807 -0.59343663\n",
      "  -1.89238945 -0.26273913 -0.07027958  3.58015013  0.91904856 -0.13519211\n",
      "  -0.65410935 -1.43116766 -0.48868227 -0.10563916  0.04319234  1.10477123\n",
      "  -0.13665143  0.         -1.44043446 -0.24085965 -2.45103311  1.41457225\n",
      "   1.41624521  2.64775678 -2.21357166  0.13020827  1.60306447 -4.47074592\n",
      "  -0.25289568 -0.92174749  0.43619265  0.05708296  3.21705363 -2.10071519\n",
      "  -0.31928516  0.          0.09264881  0.         -0.43242082 -2.68281337\n",
      "   0.16490434 -0.2934237   0.         -2.23021084 -1.13869542  2.45832156\n",
      "  -0.02187928  0.38413282  0.7545258  -1.78966282  0.5756926  -0.97419387\n",
      "   1.91055903 -0.33398371 -1.67401894  6.08593358 15.30063887  2.1253538 ]]\n",
      "20 [[ 0.08088728  0.17118363  0.44815348 -4.68022182 -0.34928815 -0.78576815\n",
      "  -1.89561007 -0.24364699 -0.15608993  3.93661175  1.03531679 -0.27015688\n",
      "  -0.83786392 -1.57225193 -0.5854146  -0.110654    0.04669386  1.35516938\n",
      "  -0.17460112 -0.12668663 -1.76606343 -0.30729937 -2.78782199  1.69612358\n",
      "   1.77878345  3.29679158 -3.00159592  1.28816228  1.80356701 -6.00583982\n",
      "  -0.33017416 -1.5251677   0.22125566  0.43532586  3.79260632 -2.58758914\n",
      "  -0.71066365  0.          0.          0.         -0.55263906 -3.09633096\n",
      "   0.46946753 -0.39692817  0.         -2.51137208 -1.44455548  2.70491864\n",
      "  -0.15786736  0.42030335  0.86732154 -2.04547091  0.64813286 -1.12900269\n",
      "   2.27393855 -0.38539601 -1.85549357  6.63676267 16.36014987  2.42015587]]\n",
      "CI: 0.742756183745583\n",
      "Consec CI: 0.6105527638190955\n",
      "MSE: 0.5349590783757189\n",
      "MSE2: 0.6067851514727777\n",
      "Subtype:  {'precisions': array([0.38297872, 0.92      ]), 'recalls': array([0.9       , 0.44230769]), 'accuracy': 0.5694444444444444, 'auroc': 0.7403846153846154}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate the model with different metrics\n",
    "test_CI, test_consec_CI = get_CI_and_consec_CI(model, data_dict[\"aging_test_df\"], data_dict[\"test_df\"], \"z0\")\n",
    "test_mse = get_mse_result(model, data_dict[\"aging_test_df\"], \"z0\")\n",
    "test_mse2 = get_mse2(model, data_dict[\"aging_test_df\"], data_dict[\"test_df\"], \n",
    "                     \"DIS_DUR_BY_CONSENTDT\", [\"z0\"], \n",
    "                     data_dict[\"observed_column_names\"], \n",
    "                     fit_intercept=False) # False for Aging CS and Aging LON, True for VAE\n",
    "subtype_dict = subtyping_aging(data_dict, model, [\"z0\"], \n",
    "                               sampled=True, # True if data in data_dict is sampled\n",
    "                               pred_dir=None, \n",
    "                               fit_intercept=False) # False for Aging CS and Aging LON, True for VAE\n",
    "print(\"CI: {}\".format(test_CI))\n",
    "print(\"Consec CI: {}\".format(test_consec_CI))\n",
    "print(\"MSE: {}\".format(test_mse))\n",
    "print(\"MSE2: {}\".format(test_mse2))\n",
    "print(\"Subtype: \", subtype_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
